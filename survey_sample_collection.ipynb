{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ipywidgets import Output\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import src.ipython_loader as loader\n",
    "\n",
    "from src.code_processing import parse_code_string, generate_linter_messages\n",
    "\n",
    "figsize = (10, 7)\n",
    "resolution = 300 # dpi\n",
    "data_path = Path('data')\n",
    "ipython_path = data_path / 'ipython_new'\n",
    "\n",
    "items, log, defects, defect_log, _ = loader.load(ipython_path, data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_close_pair(row):\n",
    "    \"\"\"Check if there is a pair of values with difference one or less.\"\"\"\n",
    "    row_values = row.values\n",
    "    return np.any(np.abs(row_values[:, None] - row_values) <= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# at least two defects\n",
    "filtered = defect_log[defect_log.sum(axis=1) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# at most difference of one in severity\n",
    "filtered *= defects.loc[filtered.columns]['severity']\n",
    "filtered = filtered[filtered.apply(has_close_pair, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the filter\n",
    "defect_log = defect_log.loc[filtered.index]\n",
    "log = log.loc[filtered.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sample(sample_size=20, random_state=42):\n",
    "    \"\"\"Sample log indexes uniformly over all tasks.\"\"\"\n",
    "    task_weights = 1 / log['item'].value_counts().reindex(log['item']).values\n",
    "    return log.sample(sample_size, random_state=random_state, weights=task_weights).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_export_dataframes(indexes):\n",
    "    \"\"\"Create submission and defect dataframes for export from given indexes.\"\"\"\n",
    "    submission_df = []\n",
    "    defect_df = []\n",
    "\n",
    "    \n",
    "    for idx in indexes:\n",
    "        row = log.loc[idx]\n",
    "        submission_df.append({\n",
    "            'submission': row['answer'],\n",
    "            'task name': items.loc[row['item']]['name'],\n",
    "            'instructions': items.loc[row['item']]['instructions']\n",
    "        })\n",
    "        \n",
    "        # Previously made defects\n",
    "        defect_history = defect_log.loc[\n",
    "            log[(log['user'] == row['user']) & (log['time'] <= row['time'])]\n",
    "            .sort_values(by='time').index\n",
    "        ].reset_index(drop=True).astype(bool)\n",
    "        \n",
    "        for defect in defect_log.loc[idx][defect_log.loc[idx] > 0].index:\n",
    "            defect_df.append({\n",
    "                'submission id': idx,\n",
    "                'defect id': defect,\n",
    "                'severity': defects.loc[defect]['severity'],\n",
    "                'name': defects.loc[defect]['defect name'],\n",
    "                'description': defects.loc[defect]['description'],\n",
    "                'code example': defects.loc[defect]['code example'],\n",
    "                'code fix example': defects.loc[defect]['code fix example'],\n",
    "                'frequency': item_profiles.loc[row['item'], defect],\n",
    "                'last encountered': (defect_history.index - defect_history[defect].cumsum().where(defect_history[defect]).ffill()).iloc[-1]\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(submission_df, index=indexes), pd.DataFrame(defect_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = []\n",
    "submission_index = []\n",
    "defect_df = []\n",
    "for idx, row in log[defect_log.sum(axis=1) >= 2].sample(20, random_state=42).iterrows():\n",
    "    submission_index.append(idx)\n",
    "    submission_row = {}\n",
    "    submission_row['submission'] = row['answer']\n",
    "    submission_row['task name'] = items.loc[row['item']]['name']\n",
    "    submission_row['instructions'] = items.loc[row['item']]['instructions']\n",
    "    submission_df.append(submission_row)\n",
    "\n",
    "    # previously made defects\n",
    "    defect_history = defect_log.loc[\n",
    "        log[(log['user'] == row['user']) & (log['time'] <= row['time'])].sort_values(by='time').index\n",
    "    ].reset_index(drop=True).astype(bool)\n",
    "\n",
    "    for defect in defect_log.loc[idx][defect_log.loc[idx] > 0].index:\n",
    "        defect_row = {}\n",
    "        defect_row['submission id'] = idx\n",
    "        defect_row['defect id'] = defect\n",
    "        defect_row['severity'] = defects.loc[defect]['severity']\n",
    "        defect_row['name'] = defects.loc[defect]['defect name']\n",
    "        defect_row['description'] = defects.loc[defect]['description']\n",
    "        defect_row['code example'] = defects.loc[defect]['code example']\n",
    "        defect_row['code fix example'] = defects.loc[defect]['code fix example']\n",
    "        defect_df.append(defect_row)\n",
    "\n",
    "submission_df = pd.DataFrame(submission_df, index=submission_index)\n",
    "defect_df = pd.DataFrame(defect_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defect_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look for uniformative entries that might pollute the survey pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty or overly long submissions\n",
    "lengths = submission_df['submission'].apply(len).sort_values(ascending=False)\n",
    "plt.figure(figsize=figsize, layout='constrained')\n",
    "plt.plot(range(len(lengths)), lengths)\n",
    "\n",
    "plt.xticks(range(len(lengths)), lengths.index, rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in lengths[(lengths > 500) | (lengths < 100)].index:\n",
    "    print(idx, submission_df.loc[idx]['submission'])\n",
    "    print('=' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duplicities - tasks\n",
    "task_names = submission_df['task name'][submission_df['task name'].duplicated(keep=False)].unique()\n",
    "for name in task_names:\n",
    "    for idx in submission_df[submission_df['task name'] == name].index:\n",
    "        print(idx, submission_df.loc[idx]['submission'])\n",
    "    print('=' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duplicities - defect pairs\n",
    "# TODO check that it works for triples\n",
    "\n",
    "ids_sets = defect_df.groupby('submission id')['defect id'].unique().apply(set)\n",
    "duplicates = ids_sets[ids_sets.duplicated(keep=False)]\n",
    "duplicates.apply(frozenset).unique()  # set in not hashable\n",
    "\n",
    "for duplicate in duplicates:\n",
    "    submission_ids = defect_df.groupby('submission id')['defect id'].apply(frozenset) == duplicate\n",
    "    submission_ids = submission_ids[submission_ids].index\n",
    "    for idx in submission_ids:\n",
    "        print(idx, submission_df.loc[idx]['submission'])\n",
    "    print(duplicate)\n",
    "    print('=' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:   \n",
    "    defect_df.to_csv(data_path / 'export' / 'defects.csv', sep=';', index_label='index')\n",
    "    submission_df.to_csv(data_path / 'export' / 'submissions.csv', sep=';', index_label='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# task history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## is the task-defect \"possible\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## characteristic defect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task-specific defect Z-scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issues in task templates - removed (handled differently)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possibly other anomalies? TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Too common\" defects are signals that something is off - Setting the threshold - binary map at different levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature - task-defect Z-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering for good representatives - big difference in scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_profiles = defect_log.groupby(log['item']).mean()\n",
    "task_counts = defect_log.groupby(log['item']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log['item']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## currently taught topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## connected to poor performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# student history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of submissions since last encountered\n",
    "defect_row['last encountered'] = (defect_history.index - defect_history[defect].cumsum().where(defect_history[defect]).ffill()).iloc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## recently repeated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## often repeated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## many times repeated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inside an already complex expression"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
