{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from matplotlib.colors import ListedColormap\n",
    "from scipy.stats import pointbiserialr\n",
    "from IPython.display import display, HTML, update_display\n",
    "from tqdm import tqdm\n",
    "\n",
    "import src.ipython_loader as loader\n",
    "from src.code_processing import generate_linter_messages\n",
    "\n",
    "figsize = (10, 7)\n",
    "resolution = 300 # dpi\n",
    "data_path = Path('data')\n",
    "ipython_path = data_path / 'ipython_new'\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items, log, defects, defect_log, code_to_defect_id = loader.load(ipython_path, data_path)\n",
    "\n",
    "#defect_log.drop(defects[['whitespace' in name for name in defects['defect name']]].index, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plotting utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_and_defect_description(task, defect):  # noqa: D103\n",
    "    task_row = items.loc[task]\n",
    "    defect_row = defects.loc[defect]\n",
    "    submissions = log[(log[\"item\"] == task) & (defect_log[defect])]\n",
    "    \n",
    "    return f\"\"\"\n",
    "    <div style=\"display: flex; justify-content: space-between; gap: 20px;\">\n",
    "        <!-- Task Section -->\n",
    "        <div style=\"width: 48%; border: 1px solid #ccc; padding: 10px; border-radius: 5px;\">\n",
    "            <h3>{task_row[\"name\"]}</h3>\n",
    "            <div><strong>Instructions:</strong><br>{task_row[\"instructions\"]}</div>\n",
    "            <div><strong>Solution:</strong><br>\n",
    "                <pre style=\"background-color: #2e2e2e; color: #f5f5f5; padding: 10px; border-radius: 5px; font-family: monospace;\">{task_row[\"solution\"]}</pre>\n",
    "            </div>\n",
    "        </div>\n",
    "        \n",
    "        <!-- Defect Section -->\n",
    "        <div style=\"width: 48%; border: 1px solid #ccc; padding: 10px; border-radius: 5px;\">\n",
    "            <h3>{defect_row[\"defect name\"]}</h3>\n",
    "            <div><strong>Defect Type:</strong> {defect_row[\"defect type\"]}</div>\n",
    "            <div><strong>Severity:</strong> {defect_row[\"severity\"]}</div>\n",
    "            <div><strong>Description:</strong><br>{defect_row[\"description\"]}</div>\n",
    "            \n",
    "            <div style=\"display: flex; justify-content: space-between; margin-top: 20px;\">\n",
    "                <div style=\"width: 48%; padding: 10px;\">\n",
    "                    <strong>Code Example:</strong><br>\n",
    "                    <pre style=\"background-color: #2e2e2e; color: #f5f5f5; padding: 10px; border-radius: 5px; font-family: monospace;\">{defect_row[\"code example\"]}</pre>\n",
    "                </div>\n",
    "                <div style=\"width: 48%; padding: 10px;\">\n",
    "                    <strong>Code Fix Example:</strong><br>\n",
    "                    <pre style=\"background-color: #2e2e2e; color: #f5f5f5; padding: 10px; border-radius: 5px; font-family: monospace;\">{defect_row[\"code fix example\"]}</pre>\n",
    "                </div>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "    \n",
    "    <!-- Code Snippet Section -->\n",
    "    <div style=\"border: 1px solid #ccc; padding: 10px; margin-top: 20px; border-radius: 5px;\">\n",
    "        <strong>Example Submission:</strong><br>\n",
    "        <pre style=\"background-color: #2e2e2e; color: #f5f5f5; padding: 10px; border-radius: 5px; font-family: monospace;\">{submissions[\"answer\"].iloc[random.randint(0, len(submissions) - 1)] if len(submissions) else 'No submissions found'}</pre>\n",
    "    </div>\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_defect_plot(matrix, title='', save=False, interactive=False, *args, **kwargs):\n",
    "    defect_names = [defects['defect name'].loc[idx][:20] for idx in matrix.columns]\n",
    "    task_names = [items['name'].loc[idx][:20] for idx in matrix.index]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(13, 7), layout=\"constrained\")\n",
    "    if interactive:\n",
    "        sns.heatmap(matrix.T, cbar=False, *args, **kwargs)\n",
    "    else:\n",
    "        sns.heatmap(matrix.T, xticklabels=task_names, yticklabels=defect_names, cbar=True, *args, **kwargs)\n",
    "        ax.tick_params(axis='x', labelsize=7)\n",
    "        ax.tick_params(axis='y', labelsize=8)\n",
    "        plt.title(title)\n",
    "    plt.xlabel(\"\")\n",
    "    plt.ylabel(\"\")\n",
    "\n",
    "    if save:\n",
    "        plt.savefig('images/' + title.lower().replace(' ', '_')[:title.find(' t=')] + '.png', dpi=300)\n",
    "\n",
    "    if interactive:\n",
    "        output_html = display(HTML(\"<b>Click a cell to see details</b>\"), display_id=True)\n",
    "\n",
    "        def on_click(event):\n",
    "            if event.inaxes == ax:\n",
    "                x = int(event.xdata)\n",
    "                y = int(event.ydata)\n",
    "                \n",
    "                if 0 <= x < len(task_names) and 0 <= y < len(defect_names):\n",
    "                    html = HTML(task_and_defect_description(matrix.index[x], matrix.columns[y]))\n",
    "                    #html = HTML(f'{x}, {y}')\n",
    "                    output_html.update(html)\n",
    "\n",
    "        fig.canvas.mpl_connect('button_press_event', on_click)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reasonableness for the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = log[['item']].merge(defect_log > 0, left_index=True, right_index=True)\n",
    "frequencies = merged.groupby('item').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.8 and lower start appearing innocent defects (augmentable assignment and so on)\n",
    "upper_limit = 0.9\n",
    "\n",
    "fig = task_defect_plot(frequencies > upper_limit, title=f\"Anomalously common task-defect pairs for threshold t={upper_limit}\", interactive=False, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "thresholds = [0.01, 0.02, 0.03, 0.04]\n",
    "defect_names = defects[\"defect name\"]\n",
    "\n",
    "all_vals = []\n",
    "for threshold in thresholds:\n",
    "    reasonable = frequencies >= threshold\n",
    "    vals = reasonable.sum(axis=0)\n",
    "    all_vals.append(vals)\n",
    "\n",
    "stack_data = pd.concat(all_vals, axis=1).fillna(0)\n",
    "stack_data.columns = [f\"t={t:.2f}\" for t in thresholds]\n",
    "\n",
    "stack_data = stack_data.loc[(stack_data.median(axis=1) + 0.1 * stack_data.max(axis=1)).sort_values(ascending=False).index]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 7), layout='constrained')\n",
    "x = np.arange(stack_data.shape[0])\n",
    "bar_width = 0.2\n",
    "n_thresholds = len(thresholds)\n",
    "\n",
    "for i, col in enumerate(stack_data.columns):\n",
    "    offset = (i - n_thresholds / 2) * bar_width + bar_width / 2\n",
    "    ax.bar(x + offset, stack_data[col], width=bar_width, label=col)\n",
    "\n",
    "\n",
    "ax.set_xticks(x, labels=[defect_names.loc[idx][:20] for idx in stack_data.index], rotation=90)\n",
    "ax.set_xlabel('Defect')\n",
    "ax.set_ylabel('Number of Reasonable Tasks')\n",
    "ax.set_title('Number of Reasonable Task-Defect Pairs as Threshold Decreases')\n",
    "ax.legend(title='Threshold')\n",
    "\n",
    "plt.savefig('images/number_of_reasonable_task-defect_pairs_as_threshold_decreases.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reasonable_threshold = 0.02\n",
    "reasonable = (frequencies >= reasonable_threshold) & (frequencies < 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = task_defect_plot(reasonable, title=f\"Reasonable Task-Defect Pairs for threshold t={reasonable_threshold:1f}\", interactive=False, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = task_defect_plot(reasonable, title=f\"Reasonable Task-Defect Pairs for threshold t={threshold}\", interactive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Characteristic for the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_score = (defect_log.groupby(log['item']).mean() - defect_log.mean()) / defect_log.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_score[reasonable == False] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = task_defect_plot(z_score, title=f\"Task-Defect Pair Z-Scores\", interactive=False, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reasonable_z_scores = z_score.stack().dropna()\n",
    "quantile = 0.8\n",
    "threshold = reasonable_z_scores.quantile(quantile)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.hist(reasonable_z_scores, bins=100, color='skyblue', edgecolor='black')\n",
    "plt.axvline(x=threshold, color='red', linestyle='--', label=f'{int(quantile * 100)}-percentile Threshold (= {round(threshold, 2)})')\n",
    "\n",
    "plt.title('Histogram of Z-Scores for Reasonable Task-Defect Pairs')\n",
    "plt.xlabel('Z-Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.savefig('images/histogram_of_z-scores_for_reasonable_task-defect_pairs.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrarcteristic = (z_score > threshold).astype(int)\n",
    "chrarcteristic[reasonable == False] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = task_defect_plot(chrarcteristic, title=f\"Characteristic Defects for Threshold t={threshold}\", interactive=False, save=True, cmap=ListedColormap(['blue', 'red']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = task_defect_plot(z_score, title=f\"Task-Defect Pair Z-Scores\", interactive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_by_topic = log.merge(items, left_on='item', right_index=True)['topic']\n",
    "defect_frequencies_by_topic = defect_log.groupby(log_by_topic).mean()\n",
    "\n",
    "topic_z_score = (defect_log.groupby(log_by_topic).mean() - defect_log.mean()) / defect_log.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_z_score[defect_frequencies_by_topic < 0.01] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 10), layout=\"constrained\")\n",
    "sns.heatmap(topic_z_score.T, vmin=-2, vmax=2, yticklabels=[defects['defect name'].loc[idx][:20] for idx in topic_z_score.columns], cmap=\"vlag\", cbar=True)\n",
    "plt.ylabel(\"\")\n",
    "plt.xlabel(\"\")\n",
    "plt.title(\"Topic-Level Defect Anomalies (Z-scores)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items[items['name'].str.contains('VelkÃ©')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Spent on Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Associated with Poor Performance Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, not_log, _, not_defect_log, _ = loader.load(ipython_path, data_path, only_correct=False)\n",
    "\n",
    "df = not_log[['item', 'correct']].merge(not_defect_log, left_index=True, right_index=True)\n",
    "\n",
    "correlations = {}\n",
    "\n",
    "# for each item\n",
    "for task_id, task_df in df.groupby('item'):\n",
    "    corr_dict = {}\n",
    "    # for each defect\n",
    "    for defect in defect_log.columns:\n",
    "        # get vectors\n",
    "        defect_presence = task_df[defect]\n",
    "        incorrect = ~task_df['correct']\n",
    "        # caluclate correlation\n",
    "        if defect_presence.nunique() > 1 and incorrect.nunique() > 1:\n",
    "            corr, _ = pointbiserialr(defect_presence, incorrect)\n",
    "            corr_dict[defect] = corr\n",
    "        else:\n",
    "            corr_dict[defect] = np.nan\n",
    "\n",
    "    correlations[task_id] = corr_dict\n",
    "\n",
    "# construct df\n",
    "performance = pd.DataFrame.from_dict(correlations, orient='index')\n",
    "performance[reasonable == False] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "~task_df['correct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_df['correct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = task_defect_plot(performance, title=\"Defect-Failure Correlation\", interactive=False, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performances = performance.stack().dropna()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.hist(performances, bins=100, color='skyblue', edgecolor='black')\n",
    "plt.title('Histogram of Task-Defect Pair Correlations with Failure')\n",
    "plt.xlabel('Z-Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.savefig('images/histogram_of_task-defect_pair_correlations_with_failure.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failure_threshold = 0.1 # performances.quantile(quantile)\n",
    "\n",
    "fig = task_defect_plot(performance > failure_threshold, title=f\"High failure rates t={failure_threshold:.2f}\", interactive=False, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = task_defect_plot(performance > failure_threshold, title=f\"High failure rates t={failure_threshold:.2f}\", interactive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some interesting takeaways (long function, unused variable), but overall does not produce any meaningful results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defect multiplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, _, multiplicity_log, _ = loader.load(ipython_path, data_path, only_presence=False)\n",
    "\n",
    "assert multiplicity_log.index.difference(log.index).empty\n",
    "\n",
    "# suppress outliers\n",
    "multiplicity_log[multiplicity_log > 10] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiplicity = (multiplicity_log > 1).mean().sort_values()\n",
    "\n",
    "plt.figure(figsize=(14, 4), layout=\"constrained\")\n",
    "\n",
    "ticks = np.arange(len(multiplicity))\n",
    "\n",
    "sns.barplot(multiplicity.values)\n",
    "plt.title(\"Mean Number of Defect Occurances per Defect\")\n",
    "plt.xlabel(\"Defect\")\n",
    "plt.ylabel(\"Mean Multiplicity\")\n",
    "plt.xticks(ticks, [defects['defect name'][idx][:20] for idx in multiplicity.index], rotation=90)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiplicity = multiplicity_log.sample(n=5000, random_state=42)\n",
    "\n",
    "multiplicity = multiplicity.melt(var_name='Defect', value_name='Count')\n",
    "multiplicity = multiplicity[multiplicity['Count'] > 0]\n",
    "\n",
    "multiplicity['Defect Name'] = multiplicity['Defect'].map(lambda x: defects['defect name'].loc[x][:20])\n",
    "\n",
    "plt.figure(figsize=(14, 6), layout=\"constrained\")\n",
    "sns.boxplot(data=multiplicity, x='Defect Name', y='Count')\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Box Plot of Defect Multiplicity per Submission\")\n",
    "plt.ylabel(\"Multiplicity (Count per Submission)\")\n",
    "plt.xlabel(\"Defect\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recency_log = []\n",
    "\n",
    "# prepare in advance to make thee computation faster\n",
    "df = log.merge(defect_log, left_index=True, right_index=True)\n",
    "df = df.sort_values(by=['user', 'time'])\n",
    "\n",
    "# for each user\n",
    "for user_id, history in tqdm(df.groupby('user')):\n",
    "    last_seen = {defect: None for defect in defect_log.columns}\n",
    "\n",
    "    for i, (idx, row) in enumerate(history.iterrows()):\n",
    "        recency_row = {}\n",
    "        for defect in defect_log.columns:\n",
    "            if row[defect] == 1:\n",
    "\n",
    "                if last_seen[defect] is None:\n",
    "                    recency_row[defect] = 0\n",
    "                else:\n",
    "                    recency_row[defect] = i - last_seen[defect]\n",
    "\n",
    "                last_seen[defect] = i\n",
    "            else:\n",
    "                recency_row[defect] = np.nan\n",
    "\n",
    "        recency_row['submission id'] = idx\n",
    "        recency_log.append(recency_row)\n",
    "\n",
    "# create dataframe\n",
    "recency_log = pd.DataFrame(recency_log).set_index('submission id')\n",
    "recency_log.index.name = 'submission id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_time_rate = (recency_log == 0)[~recency_log.isna()].mean().sort_values(ascending=True)\n",
    "\n",
    "plt.figure(figsize=(12, 6), layout=\"constrained\")\n",
    "\n",
    "ticks = np.arange(len(first_time_rate))\n",
    "\n",
    "plt.bar(ticks, first_time_rate)\n",
    "plt.title(\"Percentage of First-Time Occurances per Defect\")\n",
    "plt.ylabel(\"First-Time Rate\")\n",
    "plt.xlabel(\"Defect\")\n",
    "plt.xticks(ticks, [defects['defect name'][idx][:20] for idx in first_time_rate.index], rotation=90)\n",
    "plt.grid(axis='y')\n",
    "\n",
    "plt.savefig('images/percentage_of_first_time_occurances_per_defect.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bins\n",
    "bins = [0, 1, 2, 4, 9, 14, 19, 24, 29, np.inf]\n",
    "bin_labels = ['1', '2', '3-4', '5-9', '10-14', '15-19', '20-24', '25-29', '30+']\n",
    "recency = recency_log.apply(lambda col: pd.cut(col, bins=bins, labels=bin_labels))\n",
    "\n",
    "# histogram\n",
    "recency = recency.apply(lambda col: col.value_counts()).fillna(0).astype(int)\n",
    "\n",
    "# scaling\n",
    "recency = recency.div(recency.sum(axis=0), axis=1)\n",
    "\n",
    "# sort as the previous graph\n",
    "recency = recency.loc[:, first_time_rate.index]\n",
    "\n",
    "plt.figure(figsize=(12, 6), layout=\"constrained\")\n",
    "sns.heatmap(recency, cmap='viridis', cbar_kws={'label': 'frequency'}, xticklabels=[defects['defect name'][idx][:20] for idx in defect_log.columns])\n",
    "plt.title(\"Number of Sessions Before Defect Reoccurance\")\n",
    "plt.xlabel(\"Defect\")\n",
    "plt.ylabel(\"Recency Bin\")\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "plt.savefig('images/heatmap_of_recency_bins_per_defect.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_recency = recency_log.replace(0, np.nan).mean().sort_values()\n",
    "\n",
    "# sort as the other graphs\n",
    "recency = recency.loc[:, first_time_rate.index]\n",
    "\n",
    "plt.figure(figsize=(12, 6), layout=\"constrained\")\n",
    "\n",
    "ticks = np.arange(len(mean_recency))\n",
    "\n",
    "plt.bar(ticks, mean_recency)\n",
    "plt.title(\"Average Recency (# of Submissions Since Last Seen) per Defect\")\n",
    "plt.ylabel(\"Average Recency\")\n",
    "plt.xlabel(\"Defect\")\n",
    "plt.xticks(ticks, [defects['defect name'][idx][:20] for idx in first_time_rate.index], rotation=90)\n",
    "plt.grid(axis='y')\n",
    "\n",
    "plt.savefig('images/average_recency_per_defect.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recency_log.groupby(log['item']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recency_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Currently Taught Topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually set for topics, or by frequency in student submissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_concept_to_defects(keyword:str, tag:str):\n",
    "    if 'concepts' not in defects.columns:\n",
    "        defects['concepts'] = ['' for i in range(len(defects))]\n",
    "    mask = defects['code fix example'].apply(lambda x: True if x and 'if' in x else False)\n",
    "    mask |= defects['code example'].apply(lambda x: True if x and 'if' in x else False)\n",
    "    mask &= defects['concepts'].apply(lambda x: tag not in x)\n",
    "    defects['concepts'] += mask.apply(lambda x: tag + ' ' if x else '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_concept_to_defects('if ', 'if')\n",
    "add_concept_to_defects('for ', 'for')\n",
    "add_concept_to_defects('while ', 'while')\n",
    "add_concept_to_defects('string ', '\\'')\n",
    "add_concept_to_defects('string ', '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Opportunity Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def compute_future_opportunity(submission_id):\n",
    "    # Get submission row\n",
    "    row = log.loc[submission_id]\n",
    "    user, task, current_time = row['user'], row['item'], row['time']\n",
    "    \n",
    "    # Tasks completed up to this point\n",
    "    completed_up_to_now = log[\n",
    "        (log['user'] == user) & (log['time'] <= current_time)\n",
    "    ]['item']\n",
    "\n",
    "    # Define future tasks\n",
    "    all_tasks = sorted(frequencies.index)\n",
    "    remaining_tasks = [t for t in all_tasks if t not in completed_up_to_now]\n",
    "    if not remaining_tasks:\n",
    "        return {defect: 0.0 for defect in frequencies.columns}\n",
    "    \n",
    "    # Weight by task ID (scaled)\n",
    "    weights = np.where(remaining_tasks > task, 2, 1)\n",
    "    \n",
    "    # Get defect frequencies for those tasks\n",
    "    future_freqs = frequencies.loc[remaining_tasks]\n",
    "    \n",
    "    # Weighted average\n",
    "    weighted_avg = (future_freqs.T @ weights).to_dict()\n",
    "    return weighted_avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_future_opportunity(log.iloc[100]['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_close_pair(row):\n",
    "    \"\"\"Check if there is a pair of values with difference one or less.\"\"\"\n",
    "    row_values = row.values\n",
    "    return np.any(np.abs(row_values[:, None] - row_values) <= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# at least two defects\n",
    "filtered = defect_log[defect_log.sum(axis=1) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# at most difference of one in severity\n",
    "filtered *= defects.loc[filtered.columns]['severity']\n",
    "filtered = filtered[filtered.apply(has_close_pair, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the filter\n",
    "defect_log = defect_log.loc[filtered.index]\n",
    "log = log.loc[filtered.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# small sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_submission_html(submission_id, characteristics, threshold):\n",
    "    # Fetch submission info\n",
    "    sub = log.loc[submission_id]\n",
    "    task_id = sub['item']\n",
    "    code = sub['answer']\n",
    "    \n",
    "    task_name = items.loc[task_id, 'name']\n",
    "    instructions = items.loc[task_id, 'instructions']\n",
    "    \n",
    "    present_defects = defect_log.loc[submission_id]\n",
    "    present_defects = present_defects[present_defects == 1].index.tolist()\n",
    "\n",
    "\n",
    "    defect_rows = []\n",
    "    for defect in present_defects:\n",
    "        defect_rows.append({\n",
    "            \"Defect\": defects.loc[defect, \"defect name\"],\n",
    "            \"Description\": defects.loc[defect, \"description\"],\n",
    "            f\"Characteristic (t={threshold:.2f})\": f\"{characteristics.loc[task_id, defect]:.2f}\"\n",
    "        })\n",
    "    \n",
    "    defect_df = pd.DataFrame(defect_rows)\n",
    "    \n",
    "    html = f\"\"\"\n",
    "    <div style=\"background-color: #121212; color: #f0f0f0; font-family: 'Segoe UI', sans-serif; padding: 20px;\">\n",
    "        <div style=\"text-align: left;\">\n",
    "            <table style=\"width: 90%; margin-left: auto; border-collapse: collapse; background-color: #1e1e1e; border: 1px solid #444;\">\n",
    "                <tr>\n",
    "                    <td style=\"vertical-align: top; width: 50%; border-right: 1px solid #333; padding: 20px; text-align: left;\">\n",
    "                        <h2 style=\"color: #ffffff;\">{task_name}</h2>\n",
    "                        <p><strong>Instructions:</strong><br>{instructions}</p>\n",
    "                        <div style=\"background-color: #2b2b2b; color: #dcdcdc; padding: 15px; border-radius: 5px; overflow-x: auto; text-align: left;\">\n",
    "                            <pre style=\"margin: 0; white-space: pre-wrap;\">{code}</pre>\n",
    "                        </div>\n",
    "                    </td>\n",
    "                    <td style=\"vertical-align: top; width: 50%; padding: 20px;\">\n",
    "                        <h2 style=\"color: #ffffff;\">Detected Defects</h2>\n",
    "                        {defect_df.to_html(index=False, escape=False, border=0, justify='left', classes='defect-table')}\n",
    "                    </td>\n",
    "                </tr>\n",
    "            </table>\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    return html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify task-defect pairs where z-score > 1\n",
    "characteristic = frequencies\n",
    "threshold = 0.2\n",
    "flagged = (characteristic >= threshold)\n",
    "\n",
    "qualified = []\n",
    "\n",
    "# find all submission ids for relevant task-defect pairs\n",
    "for task, row in flagged.iterrows():\n",
    "    for defect, is_significant in row.items():\n",
    "        if is_significant:\n",
    "            submission_ids = log[(log['item'] == task) & (defect_log[defect])].index\n",
    "            for sid in submission_ids:\n",
    "                qualified.append({\n",
    "                    'submission_id': sid,\n",
    "                    'task': task,\n",
    "                    'defect': defect,\n",
    "                    'z_score': characteristic.loc[task, defect]\n",
    "                })\n",
    "\n",
    "qualified_df = pd.DataFrame(qualified)\n",
    "\n",
    "# sample 10 unique submissions\n",
    "sampled_df = qualified_df.drop_duplicates(subset='submission_id').sample(n=10, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HTML(generate_submission_html(sampled_df['submission_id'].iloc[2], characteristic, threshold)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sample(sample_size=20, random_state=42):\n",
    "    \"\"\"Sample log indexes uniformly over all tasks.\"\"\"\n",
    "    task_weights = 1 / log['item'].value_counts().reindex(log['item']).values\n",
    "    return log.sample(sample_size, random_state=random_state, weights=task_weights).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_export_dataframes(indexes):\n",
    "    \"\"\"Create submission and defect dataframes for export from given indexes.\"\"\"\n",
    "    submission_df = []\n",
    "    defect_df = []\n",
    "\n",
    "    \n",
    "    for idx in indexes:\n",
    "        row = log.loc[idx]\n",
    "        submission_df.append({\n",
    "            'submission': row['answer'],\n",
    "            'task name': items.loc[row['item']]['name'],\n",
    "            'instructions': items.loc[row['item']]['instructions']\n",
    "        })\n",
    "        \n",
    "        # Previously made defects\n",
    "        defect_history = defect_log.loc[\n",
    "            log[(log['user'] == row['user']) & (log['time'] <= row['time'])]\n",
    "            .sort_values(by='time').index\n",
    "        ].reset_index(drop=True).astype(bool)\n",
    "        \n",
    "        for defect in defect_log.loc[idx][defect_log.loc[idx] > 0].index:\n",
    "            defect_df.append({\n",
    "                'submission id': idx,\n",
    "                'defect id': defect,\n",
    "                'severity': defects.loc[defect]['severity'],\n",
    "                'name': defects.loc[defect]['defect name'],\n",
    "                'description': defects.loc[defect]['description'],\n",
    "                'code example': defects.loc[defect]['code example'],\n",
    "                'code fix example': defects.loc[defect]['code fix example'],\n",
    "                'last encountered': (defect_history.index - defect_history[defect].cumsum().where(defect_history[defect]).ffill()).iloc[-1]\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(submission_df, index=indexes), pd.DataFrame(defect_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = []\n",
    "submission_index = []\n",
    "defect_df = []\n",
    "for idx, row in log[defect_log.sum(axis=1) >= 2].sample(20, random_state=42).iterrows():\n",
    "    submission_index.append(idx)\n",
    "    submission_row = {}\n",
    "    submission_row['submission'] = row['answer']\n",
    "    submission_row['task name'] = items.loc[row['item']]['name']\n",
    "    submission_row['instructions'] = items.loc[row['item']]['instructions']\n",
    "    submission_df.append(submission_row)\n",
    "\n",
    "    # previously made defects\n",
    "    defect_history = defect_log.loc[\n",
    "        log[(log['user'] == row['user']) & (log['time'] <= row['time'])].sort_values(by='time').index\n",
    "    ].reset_index(drop=True).astype(bool)\n",
    "\n",
    "    for defect in defect_log.loc[idx][defect_log.loc[idx] > 0].index:\n",
    "        defect_row = {}\n",
    "        defect_row['submission id'] = idx\n",
    "        defect_row['defect id'] = defect\n",
    "        defect_row['severity'] = defects.loc[defect]['severity']\n",
    "        defect_row['name'] = defects.loc[defect]['defect name']\n",
    "        defect_row['description'] = defects.loc[defect]['description']\n",
    "        defect_row['code example'] = defects.loc[defect]['code example']\n",
    "        defect_row['code fix example'] = defects.loc[defect]['code fix example']\n",
    "        defect_df.append(defect_row)\n",
    "\n",
    "submission_df = pd.DataFrame(submission_df, index=submission_index)\n",
    "defect_df = pd.DataFrame(defect_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defect_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look for uniformative entries that might pollute the survey pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty or overly long submissions\n",
    "lengths = submission_df['submission'].apply(len).sort_values(ascending=False)\n",
    "plt.figure(figsize=figsize, layout='constrained')\n",
    "plt.plot(range(len(lengths)), lengths)\n",
    "\n",
    "plt.xticks(range(len(lengths)), lengths.index, rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in lengths[(lengths > 500) | (lengths < 100)].index:\n",
    "    print(idx, submission_df.loc[idx]['submission'])\n",
    "    print('=' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duplicities - tasks\n",
    "task_names = submission_df['task name'][submission_df['task name'].duplicated(keep=False)].unique()\n",
    "for name in task_names:\n",
    "    for idx in submission_df[submission_df['task name'] == name].index:\n",
    "        print(idx, submission_df.loc[idx]['submission'])\n",
    "    print('=' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duplicities - defect pairs\n",
    "# TODO check that it works for triples\n",
    "\n",
    "ids_sets = defect_df.groupby('submission id')['defect id'].unique().apply(set)\n",
    "duplicates = ids_sets[ids_sets.duplicated(keep=False)]\n",
    "duplicates.apply(frozenset).unique()  # set in not hashable\n",
    "\n",
    "for duplicate in duplicates:\n",
    "    submission_ids = defect_df.groupby('submission id')['defect id'].apply(frozenset) == duplicate\n",
    "    submission_ids = submission_ids[submission_ids].index\n",
    "    for idx in submission_ids:\n",
    "        print(idx, submission_df.loc[idx]['submission'])\n",
    "    print(duplicate)\n",
    "    print('=' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:   \n",
    "    defect_df.to_csv(data_path / 'export' / 'defects.csv', sep=';', index_label='index')\n",
    "    submission_df.to_csv(data_path / 'export' / 'submissions.csv', sep=';', index_label='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# additional filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_close_pair(row):\n",
    "    \"\"\"Check if there is a pair of values with difference one or less.\"\"\"\n",
    "    row_values = row.values\n",
    "    return np.any(np.abs(row_values[:, None] - row_values) <= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# at most difference of one in severity\n",
    "filtered *= defects.loc[filtered.columns]['severity']\n",
    "filtered = filtered[filtered.apply(has_close_pair, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the filter\n",
    "defect_log = defect_log.loc[filtered.index]\n",
    "log = log.loc[filtered.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# task history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## is the task-defect \"possible\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimum threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_by_frequency(threshold: float = 0.05):\n",
    "    \"\"\"Generate a matrix with common and uncommon task-defect pairs.\"\"\"\n",
    "    merged = log[['item']].merge(defect_log, left_index=True, right_index=True)\n",
    "    return merged.groupby('item').mean() >= threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.05\n",
    "\n",
    "kept_pairs = threshold_by_frequency(threshold)\n",
    "\n",
    "defect_names = [defects['defect name'].loc[idx] for idx in kept_pairs.columns]\n",
    "task_names = [items['name'].loc[idx] for idx in kept_pairs.index]\n",
    "\n",
    "plt.figure(figsize=(18, 10), layout=\"constrained\")\n",
    "sns.heatmap(kept_pairs.T, xticklabels=task_names, yticklabels=defect_names, cbar=True)\n",
    "plt.title(\"Sufficiently common task-defect pairs for threshold t={}\".format(threshold))\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"\")\n",
    "\n",
    "# plt.savefig('defect_anomalies.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Threshold vs percent of allowed task-defect pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 100\n",
    "remaining_fractions = []\n",
    "thresholds = list(map(lambda x: x / steps, range(steps)))\n",
    "for threshold in thresholds:\n",
    "    kept_pairs = threshold_by_frequency(threshold)\n",
    "    remaining_fractions.append(kept_pairs.values.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(layout=\"constrained\", figsize=figsize)\n",
    "\n",
    "ax.plot(thresholds, remaining_fractions, color='red', linestyle='-', marker='o', label='Cumulative')\n",
    "\n",
    "ax.set_xlabel('Threshold')\n",
    "ax.set_ylabel('Fraction left')\n",
    "ax.set_title('Threshold vs Fraction of Kept Task-Defect Pairs')\n",
    "ax.grid(True)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incremental_fractions = [remaining_fractions[i] - remaining_fractions[i + 1] for i in range(len(remaining_fractions) - 1)]\n",
    "start = 2 # for better zoom\n",
    "\n",
    "fig, ax = plt.subplots(layout=\"constrained\", figsize=figsize)\n",
    "\n",
    "ax.plot(thresholds[start:-1], incremental_fractions[start:], color='blue', linestyle='-', marker='o', label='Incremental')\n",
    "\n",
    "ax.set_xlabel('Threshold')\n",
    "ax.set_ylabel('Fraction left')\n",
    "ax.set_title('Threshold vs Fraction of Kept Task-Defect Pairs')\n",
    "ax.grid(True)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "percent of allowed submissions vs threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "individually for tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise RuntimeError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## characteristic defect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task-specific defect Z-scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_defects = (defect_log.groupby(log[\"item\"]).mean() - defect_log.mean(axis=0)) / defect_log.std(axis=0)\n",
    "highest_variance_tasks = common_defects.var(axis=1).sort_values(ascending=False)[:30].index\n",
    "defect_names = [defects['defect name'].loc[idx] for idx in defect_log.columns]\n",
    "task_names = [items['name'].loc[idx] for idx in highest_variance_tasks]\n",
    "\n",
    "plt.figure(figsize=figsize, layout=\"constrained\")\n",
    "biggest_value = common_defects.abs().values.max()\n",
    "sns.heatmap(common_defects.loc[highest_variance_tasks].T, xticklabels=task_names, yticklabels=defect_names, cmap=\"vlag\", cbar=True, vmin=-biggest_value, vmax=biggest_value)\n",
    "plt.title(\"Task-Level Defect Anomalies (Z-scores, Tasks With Highest Variance)\")\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"\")\n",
    "\n",
    "# plt.savefig('defect_anomalies.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issues in task templates removed (handled differently)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "democode_messages = items[\"democode\"].apply(generate_linter_messages)\n",
    "democode_messages = [\n",
    "    {'item': idx, 'defect': code}\n",
    "    for idx, code_message_list in democode_messages.items()\n",
    "    for code, _ in code_message_list\n",
    "]\n",
    "democode_messages = pd.DataFrame(democode_messages)\n",
    "democode_messages = democode_messages[democode_messages[\"defect\"].isin(code_to_defect_id.keys())]\n",
    "democode_messages[\"defect\"] = democode_messages[\"defect\"].replace(code_to_defect_id).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possibly other anomalies? TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Too common\" defects are signals that something is off - Setting the threshold - binary map at different levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature - task-defect Z-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering for good representatives - big difference in scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_profiles = defect_log.groupby(log['item']).mean()\n",
    "task_counts = defect_log.groupby(log['item']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log['item']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## currently taught topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## connected to poor performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# student history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of submissions since last encountered\n",
    "defect_row['last encountered'] = (defect_history.index - defect_history[defect].cumsum().where(defect_history[defect]).ffill()).iloc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## recently repeated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## often repeated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## many times repeated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inside an already complex expression"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
