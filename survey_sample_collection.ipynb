{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from matplotlib.colors import ListedColormap\n",
    "from scipy.stats import pointbiserialr\n",
    "from IPython.display import display, HTML, update_display\n",
    "from tqdm import tqdm\n",
    "\n",
    "import src.ipython_loader as loader\n",
    "from src.code_processing import generate_linter_messages\n",
    "\n",
    "save = True\n",
    "small_figsize = (8, 5)\n",
    "long_figsize = (13, 5)\n",
    "big_figsize = (13, 7)\n",
    "resolution = 300 # dpi\n",
    "binary_cmap = ListedColormap(['red', 'green'])\n",
    "data_path = Path('data')\n",
    "ipython_path = data_path / 'ipython_new'\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items, log, defects, defect_log, code_to_defect_id = loader.load(ipython_path, data_path)\n",
    "\n",
    "#defect_log.drop(defects[['whitespace' in name for name in defects['defect name']]].index, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plotting utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histogram(values, title, bins=10, cutoff=None, save=False):  # noqa: D103\n",
    "    if cutoff:\n",
    "        values[values >= cutoff] = cutoff\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    plt.hist(values, bins=bins)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Value')\n",
    "    plt.ylabel('Count')\n",
    "    plt.grid(True)\n",
    "\n",
    "    if save:\n",
    "        plt.savefig(f'images/{title.lower().replace(\" \", \"_\")}.png', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_and_defect_description(task, defect):  # noqa: D103\n",
    "    task_row = items.loc[task]\n",
    "    defect_row = defects.loc[defect]\n",
    "    submissions = log[(log[\"item\"] == task) & (defect_log[defect])]\n",
    "    \n",
    "    return f\"\"\"\n",
    "    <div style=\"display: flex; justify-content: space-between; gap: 20px;\">\n",
    "        <!-- Task Section -->\n",
    "        <div style=\"width: 48%; border: 1px solid #ccc; padding: 10px; border-radius: 5px;\">\n",
    "            <h3>{task_row[\"name\"]}</h3>\n",
    "            <div><strong>Instructions:</strong><br>{task_row[\"instructions\"]}</div>\n",
    "            <div><strong>Solution:</strong><br>\n",
    "                <pre style=\"background-color: #2e2e2e; color: #f5f5f5; padding: 10px; border-radius: 5px; font-family: monospace;\">{task_row[\"solution\"]}</pre>\n",
    "            </div>\n",
    "        </div>\n",
    "        \n",
    "        <!-- Defect Section -->\n",
    "        <div style=\"width: 48%; border: 1px solid #ccc; padding: 10px; border-radius: 5px;\">\n",
    "            <h3>{defect_row[\"defect name\"]}</h3>\n",
    "            <div><strong>Defect Type:</strong> {defect_row[\"defect type\"]}</div>\n",
    "            <div><strong>Severity:</strong> {defect_row[\"severity\"]}</div>\n",
    "            <div><strong>Description:</strong><br>{defect_row[\"description\"]}</div>\n",
    "            \n",
    "            <div style=\"display: flex; justify-content: space-between; margin-top: 20px;\">\n",
    "                <div style=\"width: 48%; padding: 10px;\">\n",
    "                    <strong>Code Example:</strong><br>\n",
    "                    <pre style=\"background-color: #2e2e2e; color: #f5f5f5; padding: 10px; border-radius: 5px; font-family: monospace;\">{defect_row[\"code example\"]}</pre>\n",
    "                </div>\n",
    "                <div style=\"width: 48%; padding: 10px;\">\n",
    "                    <strong>Code Fix Example:</strong><br>\n",
    "                    <pre style=\"background-color: #2e2e2e; color: #f5f5f5; padding: 10px; border-radius: 5px; font-family: monospace;\">{defect_row[\"code fix example\"]}</pre>\n",
    "                </div>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "    \n",
    "    <!-- Code Snippet Section -->\n",
    "    <div style=\"border: 1px solid #ccc; padding: 10px; margin-top: 20px; border-radius: 5px;\">\n",
    "        <strong>Example Submission:</strong><br>\n",
    "        <pre style=\"background-color: #2e2e2e; color: #f5f5f5; padding: 10px; border-radius: 5px; font-family: monospace;\">{submissions[\"answer\"].iloc[random.randint(0, len(submissions) - 1)] if len(submissions) else 'No submissions found'}</pre>\n",
    "    </div>\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_defect_plot(matrix, title='', save=False, interactive=False, *args, **kwargs):  # noqa: D103\n",
    "    defect_names = [defects['defect name'].loc[idx][:20] for idx in matrix.columns]\n",
    "    task_names = [items['name'].loc[idx][:20] for idx in matrix.index]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=big_figsize, layout=\"constrained\")\n",
    "    if interactive:\n",
    "        sns.heatmap(matrix.T, cbar=False, *args, **kwargs)\n",
    "    else:\n",
    "        sns.heatmap(matrix.T, xticklabels=task_names, yticklabels=defect_names, cbar=True, *args, **kwargs)\n",
    "        ax.tick_params(axis='x', labelsize=7)\n",
    "        ax.tick_params(axis='y', labelsize=8)\n",
    "        plt.title(title)\n",
    "    plt.xlabel(\"\")\n",
    "    plt.ylabel(\"\")\n",
    "\n",
    "    if save:\n",
    "        plt.savefig('images/' + title.lower().replace(' ', '_')[:title.find(' t=')] + '.png', dpi=300)\n",
    "\n",
    "    if interactive:\n",
    "        output_html = display(HTML(\"<b>Click a cell to see details</b>\"), display_id=True)\n",
    "\n",
    "        def on_click(event):\n",
    "            if event.inaxes == ax:\n",
    "                x = int(event.xdata)\n",
    "                y = int(event.ydata)\n",
    "                \n",
    "                if 0 <= x < len(task_names) and 0 <= y < len(defect_names):\n",
    "                    html = HTML(task_and_defect_description(matrix.index[x], matrix.columns[y]))\n",
    "                    #html = HTML(f'{x}, {y}')\n",
    "                    output_html.update(html)\n",
    "\n",
    "        fig.canvas.mpl_connect('button_press_event', on_click)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task-defect reasonableness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO issues in task templates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### anomalously common tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies = defect_log.groupby(log['item']).mean()\n",
    "upper_limit = 0.9\n",
    "unreasonable = frequencies > upper_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = task_defect_plot(unreasonable, title=f\"Anomalously common task-defect pairs for threshold t={upper_limit}\", interactive=False, save=save, cmap=binary_cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = task_defect_plot(unreasonable, title=f\"Anomalously common task-defect pairs for threshold t={upper_limit}\", interactive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### task-defect pairs with very few submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = defect_log.groupby(log['item']).sum()\n",
    "lower_limit = 10\n",
    "few_submissions = (counts < lower_limit).astype('int')\n",
    "unreasonable = unreasonable | few_submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = task_defect_plot(few_submissions, title=f\"Task-Defect Pairs with too Few Submissions for t={lower_limit}\", interactive=False, save=save, cmap=binary_cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = task_defect_plot(few_submissions, title=f\"Task-Defect Pairs with too Few Submissions for t={lower_limit}\", interactive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task-defect rarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0.01, 0.02, 0.03, 0.04]\n",
    "defect_names = defects[\"defect name\"]\n",
    "\n",
    "all_vals = []\n",
    "for threshold in thresholds:\n",
    "    rare = ((frequencies < threshold) | few_submissions).astype('int')\n",
    "    common = 1 - rare\n",
    "    vals = common.sum(axis=0)\n",
    "    all_vals.append(vals)\n",
    "\n",
    "stack_data = pd.concat(all_vals, axis=1).fillna(0)\n",
    "stack_data.columns = [f\"t={t:.2f}\" for t in thresholds]\n",
    "\n",
    "stack_data = stack_data.loc[(stack_data.median(axis=1) + 0.1 * stack_data.max(axis=1)).sort_values(ascending=False).index]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=long_figsize, layout='constrained')\n",
    "x = np.arange(stack_data.shape[0])\n",
    "bar_width = 0.2\n",
    "n_thresholds = len(thresholds)\n",
    "\n",
    "for i, col in enumerate(stack_data.columns):\n",
    "    offset = (i - n_thresholds / 2) * bar_width + bar_width / 2\n",
    "    ax.bar(x + offset, stack_data[col], width=bar_width, label=col)\n",
    "\n",
    "\n",
    "ax.set_xticks(x, labels=[defect_names.loc[idx][:20] for idx in stack_data.index], rotation=90)\n",
    "ax.set_xlabel('Defect')\n",
    "ax.set_ylabel('Number of Common Tasks')\n",
    "ax.set_title('Number of Common Task-Defect Pairs as Threshold Decreases')\n",
    "ax.legend(title='Threshold')\n",
    "\n",
    "if save:\n",
    "    plt.savefig('images/number_of_common_task-defect_pairs_as_threshold_decreases.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rare_threshold = 0.02\n",
    "rare = ((frequencies < threshold) | few_submissions).astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## characteristic task-defect pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_score = (defect_log.groupby(log['item']).mean() - defect_log.mean()) / defect_log.std()\n",
    "z_score[unreasonable] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = task_defect_plot(z_score, title=f\"Task-Defect Pair Z-Scores\", interactive=False, save=save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = task_defect_plot(z_score, title=f\"Task-Defect Pair Z-Scores\", interactive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reasonable_z_scores = z_score.stack().dropna()\n",
    "quantile = 0.8\n",
    "threshold = reasonable_z_scores.quantile(quantile)\n",
    "\n",
    "plt.figure(figsize=small_figsize)\n",
    "\n",
    "plt.hist(reasonable_z_scores, bins=100, color='skyblue', edgecolor='black')\n",
    "plt.axvline(x=threshold, color='red', linestyle='--', label=f'{int(quantile * 100)}-percentile Threshold (= {threshold:.2f})')\n",
    "\n",
    "plt.title('Histogram of Z-Scores for Reasonable Task-Defect Pairs')\n",
    "plt.xlabel('Z-Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "if save:\n",
    "    plt.savefig('images/histogram_of_z-scores_for_reasonable_task-defect_pairs.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characteristic_threshold = reasonable_z_scores.quantile(quantile)\n",
    "characteristic = (z_score > characteristic_threshold).astype(int)\n",
    "characteristic[unreasonable] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = task_defect_plot(characteristic, title=f\"Characteristic Defects for Threshold t={characteristic_threshold:.2f}\", interactive=False, save=save, cmap=binary_cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_by_topic = log.merge(items, left_on='item', right_index=True)['topic']\n",
    "defect_frequencies_by_topic = defect_log.groupby(log_by_topic).mean()\n",
    "\n",
    "topic_z_score = (defect_log.groupby(log_by_topic).mean() - defect_log.mean()) / defect_log.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_z_score[defect_frequencies_by_topic < 0.01] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 10), layout=\"constrained\")\n",
    "sns.heatmap(topic_z_score.T, vmin=-2, vmax=2, yticklabels=[defects['defect name'].loc[idx][:30] for idx in topic_z_score.columns], cmap=\"vlag\", cbar=True)\n",
    "plt.ylabel(\"\")\n",
    "plt.xlabel(\"\")\n",
    "plt.title(\"Topic-Level Defect Anomalies (Z-scores)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items[items['name'].str.contains('VelkÃ©')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defects[defects['defect name'].str.contains('for with redu')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## currently taught topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rejected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### time spent on task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log['relative_time_spent'] = log['responseTime'] / log.groupby('item')['responseTime'].transform('mean')\n",
    "\n",
    "# clip all submissions to X times the task mean\n",
    "clip_threshold = 5.0\n",
    "\n",
    "print('Clipping all submissions to', clip_threshold, 'times the task mean:', (log['relative_time_spent'] > clip_threshold).mean(), 'changed.')\n",
    "\n",
    "log[log['relative_time_spent'] > clip_threshold] = clip_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_spent_threshold = log['relative_time_spent'].quantile(0.90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "sns.histplot(log['relative_time_spent'], bins=1000, kde=True)\n",
    "plt.axvline(time_spent_threshold, color='red', linestyle='--', label='75th Percentile Threshold')\n",
    "plt.title(\"Distribution of Relative Time Spent per Task (Values Over 5 Clipped)\")\n",
    "plt.xlabel(\"Relative Time Spent\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "if save:\n",
    "    plt.savefig('images/distribution_of_relative_time_spent_per_task.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### associated with poor performance (locally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "_, not_log, _, not_defect_log, _ = loader.load(ipython_path, data_path, only_correct=False)\n",
    "\n",
    "df = not_log[['item', 'correct']].merge(not_defect_log, left_index=True, right_index=True)\n",
    "\n",
    "correlations = {}\n",
    "\n",
    "# for each item\n",
    "for task_id, task_df in df.groupby('item'):\n",
    "    corr_dict = {}\n",
    "    # for each defect\n",
    "    for defect in defect_log.columns:\n",
    "        # get vectors\n",
    "        defect_presence = task_df[defect]\n",
    "        incorrect = ~task_df['correct']\n",
    "        # caluclate correlation\n",
    "        if defect_presence.nunique() > 1 and incorrect.nunique() > 1:\n",
    "            corr = precision_score(incorrect, defect_presence)\n",
    "            # corr, _ = pointbiserialr(defect_presence, incorrect)\n",
    "            corr_dict[defect] = corr\n",
    "        else:\n",
    "            corr_dict[defect] = np.nan\n",
    "\n",
    "    correlations[task_id] = corr_dict\n",
    "\n",
    "# construct df\n",
    "performance = pd.DataFrame.from_dict(correlations, orient='index')\n",
    "performance[unreasonable] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = task_defect_plot(performance, title=\"Defect-Failure Precision\", interactive=False, save=save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performances = performance.stack().dropna()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.hist(performances, bins=100, color='skyblue', edgecolor='black')\n",
    "plt.title('Histogram of Task-Defect Pair Precision in Predicting Failures')\n",
    "plt.xlabel('Z-Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "\n",
    "if save:\n",
    "    plt.savefig('images/histogram_of_task-defect_pair_precision.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failure_threshold = 0.25\n",
    "# failure_threshold = performances.quantile(quantile)\n",
    "\n",
    "fig = task_defect_plot(performance > failure_threshold, title=f\"High failure rates t={failure_threshold:.2f}\", interactive=False, save=save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = task_defect_plot(performance > failure_threshold, title=f\"High failure rates t={failure_threshold:.2f}\", interactive=True, cmap=binary_cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some interesting takeaways (long function, unused variable), but overall does not produce any meaningful results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defect multiplicity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO Z-Score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, _, multiplicity_log, _ = loader.load(ipython_path, data_path, only_presence=False)\n",
    "\n",
    "assert multiplicity_log.index.difference(log.index).empty\n",
    "\n",
    "# suppress outliers\n",
    "multiplicity_log[multiplicity_log > 10] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = multiplicity_log[multiplicity_log > 0].mean().sort_values().sort_values(ascending=False)\n",
    "\n",
    "ticks = np.arange(len(means)) + 0.4\n",
    "\n",
    "plt.figure(figsize=(10, 4), layout=\"constrained\")\n",
    "plt.bar(ticks, means.values)\n",
    "\n",
    "plt.xticks(ticks,[defects['defect name'][idx][:20] for idx in means.index], rotation=90)\n",
    "plt.title(f\"Defects by Mean Multiplicity (When Occuring)\")\n",
    "plt.xlabel(\"Defect\")\n",
    "plt.ylabel(\"Mean Multiplicity\")\n",
    "\n",
    "if save:\n",
    "    plt.savefig('images/defects_by_mean_multiplicity.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiplicity = multiplicity_log[multiplicity_log > 0]\n",
    "\n",
    "multiplicity = multiplicity.melt(var_name='Defect', value_name='Count')\n",
    "multiplicity = multiplicity[multiplicity['Count'] > 0]\n",
    "\n",
    "multiplicity['Defect Name'] = multiplicity['Defect'].map(lambda x: defects['defect name'].loc[x][:20])\n",
    "\n",
    "plt.figure(figsize=(14, 6), layout=\"constrained\")\n",
    "sns.boxplot(data=multiplicity, x='Defect Name', y='Count', order=[defects['defect name'].loc[idx][:20] for idx in means.index])\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Box Plot of Defect Multiplicity\")\n",
    "plt.ylabel(\"Multiplicity (Count per Submission)\")\n",
    "plt.xlabel(\"Defect\")\n",
    "\n",
    "if save:\n",
    "    plt.savefig('images/box_plot_of_defect_multiplicity.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recency_log = []\n",
    "\n",
    "# prepare in advance to make the computation faster\n",
    "df = log.merge(defect_log, left_index=True, right_index=True)\n",
    "df[\"time\"] = pd.to_datetime(df[\"time\"])\n",
    "df = df.sort_values(by=['user', 'time'])\n",
    "\n",
    "# for each user\n",
    "for user_id, history in tqdm(df.groupby('user')):\n",
    "    last_seen = {defect: None for defect in defect_log.columns}\n",
    "\n",
    "    # iterate over history\n",
    "    for i, (idx, row) in enumerate(history.iterrows()):\n",
    "        recency_row = {}\n",
    "        for defect in defect_log.columns:\n",
    "            if row[defect] == 1:\n",
    "\n",
    "                if last_seen[defect] is None:\n",
    "                    recency_row[defect] = 0\n",
    "                else:\n",
    "                    recency_row[defect] = i - last_seen[defect]\n",
    "\n",
    "                last_seen[defect] = i\n",
    "            else:\n",
    "                recency_row[defect] = np.nan\n",
    "\n",
    "        recency_row['submission id'] = idx\n",
    "        recency_log.append(recency_row)\n",
    "\n",
    "# create dataframe\n",
    "recency_log = pd.DataFrame(recency_log).set_index('submission id')\n",
    "recency_log.index.name = 'submission id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_time_rate = (recency_log == 0)[~recency_log.isna()].mean().sort_values(ascending=True)\n",
    "\n",
    "plt.figure(figsize=(12, 6), layout=\"constrained\")\n",
    "\n",
    "ticks = np.arange(len(first_time_rate))\n",
    "\n",
    "plt.bar(ticks, first_time_rate)\n",
    "plt.title(\"Percentage of First-Time Occurances per Defect\")\n",
    "plt.ylabel(\"First-Time Rate\")\n",
    "plt.xlabel(\"Defect\")\n",
    "plt.xticks(ticks, [defects['defect name'][idx][:30] for idx in first_time_rate.index], rotation=90)\n",
    "plt.grid(axis='y')\n",
    "\n",
    "if save:\n",
    "    plt.savefig('images/percentage_of_first_time_occurances_per_defect.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bins\n",
    "bins = [0, 1, 2, 4, 9, 14, 19, 24, 29, np.inf]\n",
    "bin_labels = ['1', '2', '3-4', '5-9', '10-14', '15-19', '20-24', '25-29', '30+']\n",
    "recency = recency_log.apply(lambda col: pd.cut(col, bins=bins, labels=bin_labels))\n",
    "\n",
    "# histogram\n",
    "recency = recency.apply(lambda col: col.value_counts()).fillna(0).astype(int)\n",
    "\n",
    "# scaling\n",
    "recency = recency.div(recency.sum(axis=0), axis=1)\n",
    "\n",
    "# sort as the previous graph\n",
    "recency = recency.loc[:, first_time_rate.index]\n",
    "\n",
    "plt.figure(figsize=(12, 6), layout=\"constrained\")\n",
    "sns.heatmap(recency, cmap='viridis', cbar_kws={'label': 'frequency'}, xticklabels=[defects['defect name'][idx][:30] for idx in recency.columns])\n",
    "plt.title(\"Number of Sessions Before Defect Reoccurance\")\n",
    "plt.xlabel(\"Defect\")\n",
    "plt.ylabel(\"Recency Bin\")\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "if save:\n",
    "    plt.savefig('images/heatmap_of_recency_bins_per_defect.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_recency = recency_log.replace(0, np.nan).median()\n",
    "\n",
    "# sort as the other graphs\n",
    "mean_recency = mean_recency.loc[first_time_rate.index]\n",
    "\n",
    "plt.figure(figsize=(12, 6), layout=\"constrained\")\n",
    "\n",
    "ticks = np.arange(len(mean_recency))\n",
    "\n",
    "plt.bar(ticks, mean_recency)\n",
    "plt.title(\"Average Recency (# of Submissions Since Last Seen) per Defect\")\n",
    "plt.ylabel(\"Average Recency\")\n",
    "plt.xlabel(\"Defect\")\n",
    "plt.xticks(ticks, [defects['defect name'][idx][:30] for idx in first_time_rate.index], rotation=90)\n",
    "plt.grid(axis='y')\n",
    "\n",
    "if save:\n",
    "    plt.savefig('images/average_recency_per_defect.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## student-specific frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare in advance\n",
    "df = log.merge(defect_log, left_index=True, right_index=True)\n",
    "df[\"time\"] = pd.to_datetime(df[\"time\"])\n",
    "df = df.sort_values(by=['user', 'time'])\n",
    "\n",
    "accuracy_log = []\n",
    "\n",
    "# for each user\n",
    "for user_id, history in tqdm(df.groupby('user')):\n",
    "    correct_count = {defect: 0 for defect in defect_log.columns}\n",
    "    encounter_count = {defect: 0 for defect in defect_log.columns}\n",
    "    \n",
    "    # iterate over history\n",
    "    for i, (idx, row) in enumerate(history.iterrows()):\n",
    "        accuracy_row = {}\n",
    "        \n",
    "        task_id = row['item']\n",
    "        \n",
    "        for defect in defect_log.columns:\n",
    "            is_reasonable = not unreasonable.loc[task_id, defect]\n",
    "            if row[defect] == 0 and is_reasonable:\n",
    "                correct_count[defect] += 1\n",
    "            if row[defect] == 1 or is_reasonable:\n",
    "                encounter_count[defect] += 1\n",
    "                accuracy_row[defect] = correct_count[defect] / encounter_count[defect]\n",
    "            else:\n",
    "                accuracy_row[defect] = np.nan\n",
    "\n",
    "        accuracy_row['submission id'] = idx\n",
    "        accuracy_log.append(accuracy_row)\n",
    "    \n",
    "# create dataframe\n",
    "accuracy_log = pd.DataFrame(accuracy_log).set_index('submission id')\n",
    "accuracy_log.index.name = 'submission id'\n",
    "\n",
    "accuracy_at_least_once = accuracy_log[accuracy_log < 1]\n",
    "\n",
    "student_specific_frequency = (accuracy_log - accuracy_log.mean()) / accuracy_log.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = pd.Series(student_specific_frequency.values.flatten()).dropna().values\n",
    "\n",
    "upper_quantile = 0.90\n",
    "student_upper_threshold = np.quantile(values, upper_quantile)\n",
    "lower_quantile = 0.20\n",
    "student_lower_threshold = np.quantile(values, lower_quantile)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.hist(values, bins=100)\n",
    "\n",
    "plt.axvline(student_lower_threshold, color='red', linestyle='--', linewidth=2, label=f'{int(lower_quantile*100)}% threshold')\n",
    "plt.axvline(student_upper_threshold, color='green', linestyle='--', linewidth=2, label=f'{int(upper_quantile*100)}% threshold')\n",
    "\n",
    "plt.title('Distribution of Student-Specific Frequency')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "if save:\n",
    "    plt.savefig(f'images/distribution_of_student_specific_frequency.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_specific = (student_specific_frequency > student_upper_threshold).astype('int')\n",
    "student_specific[student_specific_frequency < student_lower_threshold] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(accuracy_at_least_once.values.flatten(), 'Distribution of User-Defect Accuracy', bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(accuracy_at_least_once.groupby(log['user']).mean().values.flatten(), 'Distribution of User-Defect Accuracy (User Averages)', bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_means = accuracy_log.mean().sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 6), layout=\"constrained\")\n",
    "\n",
    "ticks = np.arange(len(accuracy_means))\n",
    "\n",
    "plt.bar(ticks, accuracy_means)\n",
    "plt.title(\"Average Accuracy per Defect\")\n",
    "plt.ylabel(\"Average Accuracy\")\n",
    "plt.xlabel(\"Defect\")\n",
    "plt.xticks(ticks, [defects['defect name'][idx][:20] for idx in accuracy_means.index], rotation=90)\n",
    "plt.grid(axis='y')\n",
    "\n",
    "if save:\n",
    "    plt.savefig('images/average_accuracy_per_defect.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_reasonable = (~unreasonable).sum()\n",
    "\n",
    "has_reasonable = has_reasonable.loc[accuracy_means.index]\n",
    "\n",
    "plt.figure(figsize=(12, 6), layout=\"constrained\")\n",
    "\n",
    "ticks = np.arange(len(has_reasonable))\n",
    "\n",
    "plt.bar(ticks, has_reasonable)\n",
    "plt.title(\"Average Accuracy per Defect\")\n",
    "plt.ylabel(\"Average Accuracy\")\n",
    "plt.xlabel(\"Defect\")\n",
    "plt.xticks(ticks, [defects['defect name'][idx][:20] for idx in has_reasonable.index], rotation=90)\n",
    "plt.grid(axis='y')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Currently Taught Topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually set for topics, or by frequency in student submissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_concept_to_defects(keyword:str, tag:str):\n",
    "    if 'concepts' not in defects.columns:\n",
    "        defects['concepts'] = ['' for i in range(len(defects))]\n",
    "    mask = defects['code fix example'].apply(lambda x: True if x and 'if' in x else False)\n",
    "    mask |= defects['code example'].apply(lambda x: True if x and 'if' in x else False)\n",
    "    mask &= defects['concepts'].apply(lambda x: tag not in x)\n",
    "    defects['concepts'] += mask.apply(lambda x: tag + ' ' if x else '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_concept_to_defects('if ', 'if')\n",
    "add_concept_to_defects('for ', 'for')\n",
    "add_concept_to_defects('while ', 'while')\n",
    "add_concept_to_defects('string ', '\\'')\n",
    "add_concept_to_defects('string ', '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Opportunity Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tasks = items.index\n",
    "\n",
    "opportunity_log = []\n",
    "\n",
    "# prepare in advance to make the computation faster\n",
    "df = log.merge(defect_log, left_index=True, right_index=True)\n",
    "df[\"time\"] = pd.to_datetime(df[\"time\"])\n",
    "df = df.sort_values(by=['user', 'time'])\n",
    "\n",
    "# for each user\n",
    "for user_id, history in tqdm(df.groupby('user')):\n",
    "    completed_tasks = set()\n",
    "\n",
    "    # iterate over history\n",
    "    for submission_id, row in history.iterrows():\n",
    "        # unfinished tasks\n",
    "        completed_tasks.add(row['item'])\n",
    "        remaining_tasks = [t for t in all_tasks if t not in completed_tasks]\n",
    "\n",
    "        if not remaining_tasks:\n",
    "            opportunity_log.append({\n",
    "                'submission id': submission_id,\n",
    "                **{defect: 0.0 for defect in frequencies.columns}\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        weights = np.array([2.0 if t > row['item'] else 1.0 for t in remaining_tasks])\n",
    "        weighted_avg = (frequencies.loc[remaining_tasks].T @ weights) / weights.sum()\n",
    "\n",
    "        opportunity_log.append({\n",
    "            'submission id': submission_id,\n",
    "            **weighted_avg.to_dict()\n",
    "        })\n",
    "\n",
    "\n",
    "# create dataframe\n",
    "opportunity_log = pd.DataFrame(opportunity_log).set_index('submission id')\n",
    "opportunity_log.index.name = 'submission id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.hist(opportunity_log.values.flatten(), bins=100)\n",
    "plt.title('Histogram of Future Opportunities')\n",
    "plt.xlabel('Opportunity')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(True)\n",
    "\n",
    "if save:\n",
    "    plt.savefig(f'images/histogram_of_future_opportunities.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = opportunity_log.mean().sort_values().sort_values(ascending=False)\n",
    "\n",
    "ticks = np.arange(len(means)) + 0.4\n",
    "bar_width = 0.4\n",
    "\n",
    "plt.figure(figsize=(10, 4), layout=\"constrained\")\n",
    "\n",
    "plt.bar(ticks - bar_width / 2, means.values, label='Opportunity', width=bar_width)\n",
    "plt.bar(ticks + bar_width / 2, defect_log[means.index].mean().values, label='Frequency', width=bar_width)\n",
    "\n",
    "plt.xticks(ticks,[defects['defect name'][idx][:20] for idx in means.index], rotation=90)\n",
    "plt.title(f\"Defects by Mean Opportunity vs Frequency\")\n",
    "plt.xlabel(\"Defect\")\n",
    "plt.ylabel(\"Mean Opportunity\")\n",
    "plt.legend()\n",
    "\n",
    "if save:\n",
    "    plt.savefig('images/defects_by_mean_opportunity.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_opportunities = opportunity_log.groupby(log['item']).mean()\n",
    "task_opportunities = (task_opportunities - task_opportunities.mean(axis=0))\n",
    "\n",
    "fig = task_defect_plot(task_opportunities, title=\"Future Opportunity to Make Defect by Task\", interactive=False, save=save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Severity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "severity_log = defect_log * defects.loc[defect_log.columns]['severity']\n",
    "severity_log[severity_log == 0] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = severity_log.groupby(log['item']).max().mean(axis=1).sort_values()\n",
    "\n",
    "ticks = np.arange(len(means))\n",
    "\n",
    "plt.figure(figsize=(13, 4), layout=\"constrained\")\n",
    "\n",
    "plt.bar(ticks, means.values)\n",
    "\n",
    "plt.xticks(ticks, [items['name'][idx][:20] for idx in means.index], rotation=90)\n",
    "plt.title(f\"Mean Severity for Each Task\")\n",
    "plt.xlabel(\"Task\")\n",
    "plt.ylabel(\"Severity\")\n",
    "plt.tick_params(axis='x', labelsize=7)\n",
    "plt.legend()\n",
    "\n",
    "if save:\n",
    "    plt.savefig('images/mean_severity.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "differences = severity_log.apply(lambda row: -row.nlargest(2).diff().iloc[-1], axis=1).value_counts().sort_index()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.bar(differences.index, differences.values, edgecolor='black')\n",
    "plt.title('Histogram of Differences in Severity')\n",
    "plt.xlabel('Difference')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(True)\n",
    "\n",
    "if save:\n",
    "    plt.savefig(f'images/severity_differences.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# filtering before sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO too long, short, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_close_pair(row):\n",
    "    \"\"\"Check if there is a pair of values with difference one or less.\"\"\"\n",
    "    row_values = row.values\n",
    "    return np.any(np.abs(row_values[:, None] - row_values) <= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# at least two defects\n",
    "filtered = defect_log[defect_log.sum(axis=1) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# at most difference of one in severity\n",
    "filtered *= defects.loc[filtered.columns]['severity']\n",
    "filtered = filtered[filtered.apply(has_close_pair, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the filter\n",
    "defect_log = defect_log.loc[filtered.index]\n",
    "log = log.loc[filtered.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_task_defect_table(log, task_defect_table):\n",
    "    \"\"\"Expand task-defect table to feature log.\"\"\"\n",
    "    feature_log = log[['item']].join(task_defect_table, on='item')\n",
    "    feature_log.drop('item', axis=1, inplace=True)\n",
    "    return feature_log\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_values = {\n",
    "    'rare': expand_task_defect_table(log, frequencies),  # TODO expand to log\n",
    "    'characteristic': expand_task_defect_table(log, characteristic),\n",
    "    #'currently_taught': currently_taught,\n",
    "    #'student_frequency': student_frequency_log,\n",
    "    #'multiplicity': multiplicity_log,\n",
    "    # 'recently_fixed': recently_fixed_log,\n",
    "    'severity': severity_log.loc[log.index],\n",
    "}\n",
    "\n",
    "features = {\n",
    "    'rare': expand_task_defect_table(log, ~reasonable).astype('int'),\n",
    "    'characteristic': expand_task_defect_table(log, characteristic).astype('int'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reasonable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characteristic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_submission_html(submission_id, feature):\n",
    "    \"\"\"Simulate a decision based on the value of single feature.\"\"\"\n",
    "    task_id = log.loc[submission_id, 'item']\n",
    "    \n",
    "    present_defects = defect_log.loc[submission_id]\n",
    "    present_defects = present_defects[present_defects == 1].index.tolist()\n",
    "\n",
    "\n",
    "    defect_rows = []\n",
    "    for defect in present_defects:\n",
    "        defect_rows.append({\n",
    "            \"Defect\": defects.loc[defect, \"defect name\"],\n",
    "            \"Description\": defects.loc[defect, \"description\"],\n",
    "            f\"{feature}\": f\"{feature_values[feature].loc[submission_id, defect]:.2f}\"\n",
    "        })\n",
    "    \n",
    "    defect_df = pd.DataFrame(defect_rows)\n",
    "    \n",
    "    html = f\"\"\"\n",
    "    <div style=\"background-color: #121212; color: #f0f0f0; font-family: 'Segoe UI', sans-serif; padding: 20px;\">\n",
    "        <div style=\"text-align: left;\">\n",
    "            <table style=\"width: 90%; margin-left: auto; border-collapse: collapse; background-color: #1e1e1e; border: 1px solid #444;\">\n",
    "                <tr>\n",
    "                    <td style=\"vertical-align: top; width: 50%; border-right: 1px solid #333; padding: 20px; text-align: left;\">\n",
    "                        <h2 style=\"color: #ffffff;\">{items.loc[task_id, 'name']}</h2>\n",
    "                        <p><strong>Instructions:</strong><br>{items.loc[task_id, 'instructions']}</p>\n",
    "                        <div style=\"background-color: #2b2b2b; color: #dcdcdc; padding: 15px; border-radius: 5px; overflow-x: auto; text-align: left;\">\n",
    "                            <pre style=\"margin: 0; white-space: pre-wrap;\">{log.loc[submission_id,'answer']}</pre>\n",
    "                        </div>\n",
    "                    </td>\n",
    "                    <td style=\"vertical-align: top; width: 50%; padding: 20px;\">\n",
    "                        <h2 style=\"color: #ffffff;\">Detected Defects</h2>\n",
    "                        {defect_df.to_html(index=False, escape=False, border=0, justify='left', classes='defect-table')}\n",
    "                    </td>\n",
    "                </tr>\n",
    "            </table>\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    return html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'rare'\n",
    "\n",
    "# identify submissions where feature is represented\n",
    "sampled_df = log[features[feature].sum(axis=1) > 0]\n",
    "\n",
    "# sample 10 unique submissions\n",
    "sampled_df = sampled_df.sample(n=10, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HTML(generate_submission_html(sampled_df.index[3], feature)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# survey sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "def greedy_sample(features, log, n_samples=200, seed=42):\n",
    "    \"\"\"Sample log indexes using a greedy algorithm to balance features and maximize task coverage.\"\"\"\n",
    "    random.seed(seed)\n",
    "\n",
    "    sample = []\n",
    "    feature_counts = feature_counts = pd.Series(0, index=features.keys())\n",
    "    task_counts = pd.Series(0, index=log['item'].unique())\n",
    "\n",
    "    for _ in tqdm(range(n_samples)):\n",
    "        # least represented feature\n",
    "        feature = feature_counts.idxmin()\n",
    "\n",
    "        # filter submissions with feature and not in the sample\n",
    "        candidates = features[feature]\n",
    "        candidates = candidates[candidates.sum(axis=1) > 0].index.difference(sample)\n",
    "        \n",
    "        if candidates.empty:\n",
    "            print(\"[WARNING] No candidates left for feature, skipping...\")\n",
    "            feature_counts[feature] += 1\n",
    "            continue\n",
    "\n",
    "        # filter submissions with yet unused task\n",
    "        task_indices = task_counts[task_counts == task_counts.min()].index\n",
    "        task_candidates = log.loc[candidates]\n",
    "        task_candidates = task_candidates[task_candidates['item'].apply(lambda x: x in task_indices)].index\n",
    "\n",
    "        if not task_candidates.empty:\n",
    "            choice = random.choice(task_candidates)\n",
    "            sample.append(choice)\n",
    "            task_counts[log.loc[choice, 'item']] += 1\n",
    "        else:\n",
    "            print(\"[WARNING] No candidates left for task, choosing randomly...\")\n",
    "            sample.append(random.choice(candidates))\n",
    "    return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = greedy_sample(features, log, n_samples=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_freq = defect_log.loc[sample].mean()\n",
    "global_freq = defect_log.mean()\n",
    "uniform = pd.Series(1 / len(defect_log.columns), index=defect_log.columns)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Sample': sample_freq,\n",
    "    'Global': global_freq,\n",
    "    'Uniform': uniform\n",
    "}).sort_values(by='Global', ascending=False)\n",
    "\n",
    "labels = [defects['defect name'][idx][:20] for idx in df.index]\n",
    "ticks = np.arange(len(df))\n",
    "\n",
    "bar_width = 0.4\n",
    "plt.figure(figsize=(13, 5), layout='constrained')\n",
    "\n",
    "# sample vs global\n",
    "plt.bar(ticks - bar_width/2, df['Global'], width=bar_width, label='Global', color='lightgray')\n",
    "plt.bar(ticks + bar_width/2, df['Sample'], width=bar_width, label='Sample', color='steelblue')\n",
    "\n",
    "# uniform\n",
    "plt.plot(ticks, df['Uniform'], color='green', linestyle='--', label='Uniform')\n",
    "\n",
    "plt.xticks(ticks, labels, rotation=90)\n",
    "plt.ylabel(\"Defect Frequency\")\n",
    "plt.title(\"Defect Distribution: Sample vs Global vs Uniform\")\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(f'images/sampled_defect_distribution.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_freq = log.loc[sample]['item'].value_counts(normalize=True)\n",
    "global_freq = log['item'].value_counts(normalize=True)\n",
    "uniform = pd.Series(1 / log['item'].nunique(), index=log['item'].unique())\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Sample': sample_freq,\n",
    "    'Global': global_freq,\n",
    "    'Uniform': uniform\n",
    "}).sort_values(by='Global', ascending=False)\n",
    "\n",
    "labels = [items['name'].loc[idx][:20] for idx in df.index]\n",
    "ticks = np.arange(len(df))\n",
    "\n",
    "bar_width = 0.4\n",
    "plt.figure(figsize=(13, 5), layout='constrained')\n",
    "\n",
    "# sample vs global\n",
    "plt.bar(ticks - bar_width/2, df['Global'], width=bar_width, label='Global', color='lightgray')\n",
    "plt.bar(ticks + bar_width/2, df['Sample'], width=bar_width, label='Sample', color='steelblue')\n",
    "\n",
    "# uniform\n",
    "plt.plot(ticks, df['Uniform'], color='green', linestyle='--', label='Uniform')\n",
    "\n",
    "plt.xticks(ticks, labels, rotation=90)\n",
    "plt.tick_params(axis='x', labelsize=7)\n",
    "plt.ylabel(\"Task Frequency\")\n",
    "plt.title(\"Task Distribution: Sample vs Global vs Uniform\")\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(f'images/sampled_task_distribution.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_counts = pd.DataFrame({\n",
    "    name: pd.Series(df.values.flatten()).value_counts()\n",
    "    for name, df in features.items()\n",
    "}).fillna(0).astype(int)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13, 5), layout='constrained')\n",
    "feature_counts.T.plot(kind='bar', stacked=True, colormap='tab10', ax=ax)\n",
    "\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.ylabel(\"Number of Occurances\")\n",
    "plt.title(\"Stacked Bar Plot of Feature Values in the Sample\")\n",
    "plt.legend(title=\"Values\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "plt.savefig(f'images/sampled_feature_distribution.png', dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
