{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ipywidgets import Output\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "\n",
    "from src.code_processing import parse_code_string, generate_linter_messages\n",
    "\n",
    "figsize = (10, 7)\n",
    "resolution = 300 # dpi\n",
    "data_path = Path('data')\n",
    "ipython_path = data_path / 'ipython_new'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load ipython items\n",
    "items = pd.read_csv(ipython_path / 'item.csv', sep=\";\", index_col=0)\n",
    "\n",
    "# drop unused columns\n",
    "items = items[['name', 'instructions', 'solution', 'democode']]\n",
    "# extract user instructions\n",
    "items[\"instructions\"] = items[\"instructions\"].apply(lambda x: eval(x)[0][1])\n",
    "# extract and decode example solutions\n",
    "items[\"solution\"] = items[\"solution\"].apply(lambda x: eval(x)[0][1]).apply(parse_code_string)\n",
    "items[\"democode\"] = items[\"democode\"].apply(lambda x: eval(x)[0][1]).apply(parse_code_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the ipython log\n",
    "log = pd.read_csv(ipython_path / 'log.csv', sep=\";\")\n",
    "\n",
    "# drop unused columns\n",
    "log = log[[\"id\", \"user\", \"item\", \"answer\", \"correct\", \"responseTime\", \"time\"]]\n",
    "# correct data types\n",
    "log[\"time\"] = pd.to_datetime(log[\"time\"])\n",
    "log[\"correct\"] = log[\"correct\"].astype(bool)\n",
    "# drop problematic rows\n",
    "log.dropna(inplace=True)\n",
    "log.drop_duplicates(inplace=True)\n",
    "# decode submissions\n",
    "log[\"answer\"] = log[\"answer\"].apply(parse_code_string)\n",
    "# only correct answers\n",
    "log = log[log[\"correct\"]]\n",
    "log.drop('correct', axis=1, inplace=True)\n",
    "# only one answer per session\n",
    "log = log.reset_index().groupby([\"user\", \"item\"], as_index=False).last().set_index(\"index\")\n",
    "# sorted by time\n",
    "log.sort_values(by='time', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only items with at least 100 (correct) submission\n",
    "items = items.loc[items.index.isin((log[\"item\"].value_counts() > 100).index)]\n",
    "\n",
    "# filter them out of the log also\n",
    "log = log[log[\"item\"].isin(items.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the defect table\n",
    "defects = pd.read_csv(data_path / 'defects.csv')\n",
    "\n",
    "# drop unused columns\n",
    "defects = defects[[\"defect name\", \"EduLint code\", \"defect type\", \"description\", \"code example\", \"code fix example\", \"severity\", \"id\"]]\n",
    "# drop defects not detected by EduLint\n",
    "defects.dropna(subset=[\"EduLint code\"], inplace=True)\n",
    "# convert EduLint codes from string to tuple\n",
    "defects[\"EduLint code\"] = defects[\"EduLint code\"].apply(lambda x: tuple(map(str.strip, x.split(\",\"))))\n",
    "# drop the \"missing docstring\" defect (not really appropriate in the context)\n",
    "# drop the \"mixed indentation\" defect (it is exceptionally noisy - errors during logging, students copy-pasting, ...)\n",
    "defects.drop([66, 4], axis=0, inplace=True)\n",
    "# create a dictionary mapping EduLint codes to the index of the associated defect\n",
    "code_to_defect_id = {val: idx for idx, val in defects['EduLint code'].explode().items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the EduLint messages corresponding to the entries in the ipython log\n",
    "# open the message log\n",
    "messages = pd.read_csv(ipython_path / 'message_log.csv', index_col=0, header=0)\n",
    "\n",
    "# remove some of the messages associated with the \"trailing whitespace\" defect (they are likely logging errors)\n",
    "messages = messages[~messages['message'].isin(['no newline at end of file', 'trailing whitespace'])]\n",
    "\n",
    "# keep only the messages still in the ipython log\n",
    "messages = messages[messages[\"log entry\"].isin(log.index)]\n",
    "\n",
    "# keep only messages with an associated defect\n",
    "messages = messages[messages[\"defect\"].isin(code_to_defect_id.keys())]\n",
    "\n",
    "# use defect ids instead of message codes\n",
    "messages[\"defect\"] = messages[\"defect\"].replace(code_to_defect_id).astype(int)\n",
    "\n",
    "messages.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize defects\n",
    "defect_log = pd.crosstab(messages[\"log entry\"], messages[\"defect\"]).reindex(log.index, fill_value=0)\n",
    "\n",
    "# replace defect counts with presence\n",
    "defect_log = (defect_log > 0).astype(int)\n",
    "\n",
    "# keep only detected defects\n",
    "defects = defects.loc[defects.index.isin(defect_log.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment with other options then mean\n",
    "item_profiles = defect_log.groupby(log['item']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = []\n",
    "submission_index = []\n",
    "defect_df = []\n",
    "for idx, row in log[defect_log.sum(axis=1) >= 2].sample(20, random_state=42).iterrows():\n",
    "    submission_index.append(idx)\n",
    "    submission_row = {}\n",
    "    submission_row['submission'] = row['answer']\n",
    "    submission_row['task name'] = items.loc[row['item']]['name']\n",
    "    submission_row['instructions'] = items.loc[row['item']]['instructions']\n",
    "    submission_df.append(submission_row)\n",
    "\n",
    "    # previously made defects\n",
    "    defect_history = defect_log.loc[\n",
    "        log[(log['user'] == row['user']) & (log['time'] <= row['time'])].sort_values(by='time').index\n",
    "    ].reset_index(drop=True).astype(bool)\n",
    "\n",
    "    for defect in defect_log.loc[idx][defect_log.loc[idx] > 0].index:\n",
    "        defect_row = {}\n",
    "        defect_row['submission id'] = idx\n",
    "        defect_row['severity'] = defects.loc[defect]['severity']\n",
    "        defect_row['name'] = defects.loc[defect]['defect name']\n",
    "        defect_row['description'] = defects.loc[defect]['description']\n",
    "        defect_row['code example'] = defects.loc[defect]['code example']\n",
    "        defect_row['code fix example'] = defects.loc[defect]['code fix example']\n",
    "        defect_row['frequency'] = item_profiles.loc[row['item'], defect]\n",
    "        # number of submissions since last encountered\n",
    "        defect_row['last encountered'] = (defect_history.index - defect_history[defect].cumsum().where(defect_history[defect]).ffill()).iloc[-1]\n",
    "        # TODO impact\n",
    "        defect_df.append(defect_row)\n",
    "\n",
    "submission_df = pd.DataFrame(submission_df, index=submission_index)\n",
    "defect_df = pd.DataFrame(defect_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:   \n",
    "    defect_df.to_csv(data_path / 'export' / 'defects.csv', sep=';', index_label='index')\n",
    "    submission_df.to_csv(data_path / 'export' / 'submissions.csv', sep=';', index_label='index')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
