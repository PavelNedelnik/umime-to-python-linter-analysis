{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from src.code_processing import parse_code_string\n",
    "from src.utils import split_users\n",
    "\n",
    "CONFIG = {\n",
    "    \"version\": \"0.0.0\",\n",
    "    \"only_correct\": True,\n",
    "    \"only_final\": True,\n",
    "    \"notes\": \"Final version of the dataset.\",\n",
    "}\n",
    "\n",
    "DATA_PATH = Path(\"data\")\n",
    "IPYTHON_PATH = Path(\"data\") / \"ipython_new\"\n",
    "OUTPUT_PATH = DATA_PATH / \"datasets\" / ('ipython_' + CONFIG[\"version\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# Loading and cleaning task information (items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load items data\n",
    "items = pd.read_csv(IPYTHON_PATH / \"item.csv\", sep=\";\", index_col=0)\n",
    "\n",
    "# Keep only relevant columns\n",
    "items = items[[\"name\", \"instructions\", \"solution\", \"democode\"]]\n",
    "\n",
    "# Extract user instructions\n",
    "items[\"instructions\"] = items[\"instructions\"].apply(lambda x: eval(x)[0][1])\n",
    "\n",
    "# Extract and decode example solutions\n",
    "items[\"solution\"] = items[\"solution\"].apply(lambda x: eval(x)[0][1]).apply(parse_code_string)\n",
    "items[\"democode\"] = items[\"democode\"].apply(lambda x: eval(x)[0][1]).apply(parse_code_string)\n",
    "\n",
    "# order by difficulty\n",
    "ps_order = [\n",
    "    \"Proměnné a číselné výrazy\",\n",
    "    \"Cyklus for\",\n",
    "    \"Logické výrazy\",\n",
    "    \"Podmíněný příkaz (if): základy\",\n",
    "    \"Cyklus for s vnořenou podmínkou\",\n",
    "    \"Cyklus while\",\n",
    "    \"Podmíněný příkaz (if): těžší\",\n",
    "    \"Posloupnosti\",\n",
    "    \"Úpravy programů\",\n",
    "    \"Řízení výpočtu\",\n",
    "    \"Textové obrázky\",\n",
    "    \"Řetězce: základy\",\n",
    "    \"Seznamy\",\n",
    "    \"Řetězce: těžší\",\n",
    "    \"Seznamy a řetězce: vnořené\",\n",
    "    \"Slovníky\",\n",
    "    \"Záludné\",\n",
    "]\n",
    "\n",
    "# load problem sets\n",
    "ps = pd.read_csv(IPYTHON_PATH / \"ps.csv\", index_col=0, header=0, sep=\";\")\n",
    "ps = ps[ps[\"url\"].apply(lambda x: \"interaktivni-python\" in x)][[\"topic\", \"ordering\"]]\n",
    "ps.rename(columns={\"ordering\": \"topic order\"}, inplace=True)\n",
    "ps[\"difficulty order\"] = ps[\"topic\"].apply(lambda x: ps_order.index(x))\n",
    "\n",
    "# load mapping to items\n",
    "item_to_ps = pd.read_csv(IPYTHON_PATH / \"ps_problem.csv\", index_col=0, header=0, sep=\";\")\n",
    "item_to_ps = item_to_ps[\n",
    "    item_to_ps[\"problem\"].apply(lambda x: x in items.index) & item_to_ps[\"ps\"].apply(lambda x: x in ps.index)\n",
    "]\n",
    "\n",
    "# add to items\n",
    "keep = items.columns.union(ps.columns).tolist() + [\"id\"]\n",
    "items = (\n",
    "    items.reset_index(names=\"id\")\n",
    "    .merge(item_to_ps, left_on=\"id\", right_on=\"problem\")\n",
    "    .merge(ps, left_on=\"ps\", right_index=True)[keep]\n",
    ")\n",
    "items.set_index(\"id\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# Loading and cleaning submissions (log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load log data\n",
    "log = pd.read_csv(IPYTHON_PATH / \"log.csv\", sep=\";\")\n",
    "\n",
    "# Keep only relevant columns\n",
    "log = log[[\"id\", \"user\", \"item\", \"answer\", \"correct\", \"responseTime\", \"time\"]]\n",
    "\n",
    "# Convert time column to datetime and correct data types\n",
    "log[\"time\"] = pd.to_datetime(log[\"time\"])\n",
    "log[\"correct\"] = log[\"correct\"].astype(bool)\n",
    "\n",
    "# Decode submissions\n",
    "log[\"answer\"] = log[\"answer\"].dropna().apply(parse_code_string)\n",
    "\n",
    "# Sort by time\n",
    "log.sort_values(\"time\", inplace=True)\n",
    "\n",
    "# Drop problematic rows\n",
    "log.dropna(inplace=True)\n",
    "log.drop_duplicates(inplace=True)\n",
    "\n",
    "# Keep only submissions with at least 20 characters\n",
    "log = log[log[\"answer\"].map(len) >= 20]\n",
    "\n",
    "# Keep only users with at least 5 submissions\n",
    "log = log[log[\"user\"].map(log[\"user\"].value_counts()) >= 5]\n",
    "\n",
    "# Keep only sessions lasting at least 1 minute\n",
    "log = log[log[\"responseTime\"] >= 6e4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# Additional filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out items with duplicate names\n",
    "duplicate_names = items[\"name\"].value_counts() > 1\n",
    "duplicate_names = duplicate_names[duplicate_names].index\n",
    "if len(duplicate_names) > 0:\n",
    "    for item_name in duplicate_names:\n",
    "        # keep only the first entry in items\n",
    "        duplicate_entries = items[items[\"name\"] == item_name].index\n",
    "        shared_id = duplicate_entries[0]\n",
    "        for id in duplicate_entries[1:]:\n",
    "            # drop from items\n",
    "            if id != shared_id:\n",
    "                items = items[items.index != id]\n",
    "            # propagate shared id to log\n",
    "            log.loc[log[\"item\"] == id, \"item\"] = shared_id\n",
    "\n",
    "# Keep only items with at least 100 submissions\n",
    "valid_items = items.index.isin((log[\"item\"].value_counts() > 100).index)\n",
    "items = items.loc[valid_items]\n",
    "\n",
    "# Filter them out of the log also\n",
    "log = log[log[\"item\"].isin(items.index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# Loading and cleaning defect information (defects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load defects data\n",
    "defects = pd.read_csv(DATA_PATH / \"defects.csv\")\n",
    "\n",
    "# Keep only relevant columns\n",
    "defects = defects[\n",
    "    [\n",
    "        \"defect name\",\n",
    "        \"EduLint code\",\n",
    "        \"defect type\",\n",
    "        \"description\",\n",
    "        \"code example\",\n",
    "        \"code fix example\",\n",
    "        \"severity\",\n",
    "        \"id\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "# Drop defects not detected by EduLint\n",
    "defects.dropna(subset=[\"EduLint code\"], inplace=True)\n",
    "\n",
    "# Convert EduLint codes from string to tuple\n",
    "defects[\"EduLint code\"] = defects[\"EduLint code\"].apply(lambda x: tuple(map(str.strip, x.split(\",\"))))\n",
    "\n",
    "# Drop noisy defects\n",
    "defects.drop([66, 4], axis=0, inplace=True)\n",
    "\n",
    "# Create a dictionary mapping EduLint codes to defect indices\n",
    "code_to_defect_id = {val: idx for idx, val in defects[\"EduLint code\"].explode().items()}\n",
    "\n",
    "# Replace missing values with empty strings\n",
    "defects[\"code fix example\"] = defects[\"code fix example\"].fillna(\"\")\n",
    "defects[\"code example\"] = defects[\"code example\"].fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# Loading detected defects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load message log data\n",
    "messages = pd.read_csv(IPYTHON_PATH / \"message_log.csv\", index_col=0, header=0)\n",
    "\n",
    "# Remove some of the messages associated with the \"trailing whitespace\" defect\n",
    "messages = messages[~messages[\"message\"].isin([\"no newline at end of file\", \"trailing whitespace\"])]\n",
    "\n",
    "# Keep only the messages still in the ipython log\n",
    "messages = messages[messages[\"log entry\"].isin(log.index)]\n",
    "\n",
    "# Keep only messages with an associated defect\n",
    "messages = messages[messages[\"defect\"].isin(code_to_defect_id.keys())]\n",
    "\n",
    "# Use defect IDs instead of message codes\n",
    "messages[\"defect\"] = messages[\"defect\"].replace(code_to_defect_id).astype(int)\n",
    "\n",
    "messages.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Create a defect log matrix\n",
    "defect_log = pd.crosstab(messages[\"log entry\"], messages[\"defect\"]).reindex(log.index, fill_value=0)\n",
    "\n",
    "# Keep only correct answers\n",
    "if CONFIG[\"only_correct\"]:\n",
    "    log = log[log[\"correct\"]]\n",
    "\n",
    "# Keep only one answer per session\n",
    "if CONFIG[\"only_final\"]:\n",
    "    log = log.reset_index().groupby([\"user\", \"item\"], as_index=False).last().set_index(\"index\")\n",
    "\n",
    "# Apply the filters to the defect log\n",
    "defect_log = defect_log.loc[log.index]\n",
    "\n",
    "# Keep only detected defects\n",
    "encountered_defects = defect_log.sum() > 0\n",
    "encountered_defects = encountered_defects[encountered_defects > 0]\n",
    "defects = defects.loc[defects.index.isin(encountered_defects.index)]\n",
    "defect_log = defect_log.loc[:, defects.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Shortened names for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_text(text: str, max_length: int=20):\n",
    "    \"\"\"Truncate text if it exceeds the maximum length.\"\"\"\n",
    "    if len(text) > max_length:\n",
    "        return text[:max_length - 3] + '...'\n",
    "    return text\n",
    "\n",
    "def abbreviate_and_truncate_text(text: str, ordered_abbreviations: dict | None=None, max_length: int=20):\n",
    "    \"\"\"Shorten text by applying a list of abbreviations and truncating if necessary.\"\"\"\n",
    "    current_text = text\n",
    "\n",
    "    if ordered_abbreviations:\n",
    "        for full_word, abbr in ordered_abbreviations.items():\n",
    "            # Use regex with word boundaries to ensure we replace full words only\n",
    "            pattern = re.escape(full_word)\n",
    "            current_text = re.sub(pattern, abbr, current_text, flags=re.IGNORECASE)\n",
    "\n",
    "            if len(current_text) <= max_length:\n",
    "                return current_text\n",
    "    \n",
    "    return truncate_text(current_text)\n",
    "\n",
    "ordered_abbreviations = {\n",
    "    'whitespace': 'ws',\n",
    "    'constant': 'const',\n",
    "    'variable': 'var',\n",
    "    'function': 'func',\n",
    "    'parameter': 'param',\n",
    "    'expression': 'expr',\n",
    "    'argument': 'arg',\n",
    "    'operator': 'op',\n",
    "    'operation': 'op',\n",
    "    'augmentable': 'aug',\n",
    "    'assignment': 'assign',\n",
    "    'container': 'cont',\n",
    "    'statement': 'stmt',\n",
    "    'arithmetic': 'arith',\n",
    "    'condition': 'cond',\n",
    "    'identifier': 'identif',\n",
    "    'multiple': 'multi',\n",
    "    'redundant': 'redun',\n",
    "    'necessary': 'necces',\n",
    "    'comparison': 'compar',\n",
    "    'negated': 'neg',\n",
    "    'unreachable': 'unreach',\n",
    "    'inappropriate': 'inapp',\n",
    "    'parenthesis': '()',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defects['display name'] = defects['defect name'].apply(lambda x: abbreviate_and_truncate_text(x, ordered_abbreviations))\n",
    "items['display name'] = items['name'].apply(truncate_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Splitting to train, evaluation and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "development_mask, evaluation_mask, hold_out_mask = split_users(log, train_pct=0.8, val_pct=0.1, test_pct=0.1, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# Combining to a final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "\n",
    "json.dump(CONFIG, open(OUTPUT_PATH / f\"config_{CONFIG['version']}.json\", \"w\"))\n",
    "\n",
    "items.to_csv(OUTPUT_PATH / \"items.csv\")\n",
    "defects.to_csv(OUTPUT_PATH / \"defects.csv\")\n",
    "\n",
    "for dir, mask in zip(['development', 'evaluation', 'hold_out'], [development_mask, evaluation_mask, hold_out_mask]):\n",
    "    path = OUTPUT_PATH / dir\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    log[mask].to_csv(path / \"log.csv\")\n",
    "    defect_log[mask].to_csv(path / \"defect_log.csv\")\n",
    "\n",
    "# multiple codes might map to one defect id\n",
    "json.dump(code_to_defect_id, open(OUTPUT_PATH / \"code_to_defect_id.json\", \"w\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
