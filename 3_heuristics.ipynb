{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up and global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "from matplotlib.colors import ListedColormap\n",
    "from IPython.display import display, HTML\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GroupKFold, cross_val_score, LeaveOneGroupOut, train_test_split\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import src.ipython_loader as loader\n",
    "from src.prioritization import PrioritizationModel, DummyTaskPrioritizer\n",
    "\n",
    "RESOLUTION = 300\n",
    "VERSION = '0.0.0'\n",
    "DATASET_PATH = Path('data') / 'datasets' / f'ipython_{VERSION}'\n",
    "OUTPUT_PATH = DATASET_PATH / 'heuristics'\n",
    "BINARY_CMAP = ListedColormap(['red', 'green'])\n",
    "\n",
    "IMAGE_DIR = Path('images') / \"heuristics\"\n",
    "\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "os.makedirs(IMAGE_DIR, exist_ok=True)\n",
    "\n",
    "MIN_TASK_DEFECT_SUBMISSIONS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_text(text: str, max_length: int=20):\n",
    "    \"\"\"Truncate text if it exceeds the maximum length.\"\"\"\n",
    "    if len(text) > max_length:\n",
    "        return text[:max_length - 3] + '...'\n",
    "    return text\n",
    "\n",
    "def abbreviate_and_truncate_text(text: str, ordered_abbreviations: dict | None=None, max_length: int=20):\n",
    "    \"\"\"Shorten text by applying a list of abbreviations and truncating if necessary.\"\"\"\n",
    "    current_text = text\n",
    "\n",
    "    if ordered_abbreviations:\n",
    "        for full_word, abbr in ordered_abbreviations.items():\n",
    "            # Use regex with word boundaries to ensure we replace full words only\n",
    "            pattern = re.escape(full_word)\n",
    "            current_text = re.sub(pattern, abbr, current_text, flags=re.IGNORECASE)\n",
    "\n",
    "            if len(current_text) <= max_length:\n",
    "                return current_text\n",
    "    \n",
    "    return truncate_text(current_text)\n",
    "\n",
    "ordered_abbreviations = {\n",
    "    'whitespace': 'ws',\n",
    "    'constant': 'const',\n",
    "    'variable': 'var',\n",
    "    'function': 'func',\n",
    "    'parameter': 'param',\n",
    "    'expression': 'expr',\n",
    "    'argument': 'arg',\n",
    "    'operator': 'op',\n",
    "    'operation': 'op',\n",
    "    'augmentable': 'aug',\n",
    "    'assignment': 'assign',\n",
    "    'container': 'cont',\n",
    "    'statement': 'stmt',\n",
    "    'arithmetic': 'arith',\n",
    "    'condition': 'cond',\n",
    "    'identifier': 'identif',\n",
    "    'multiple': 'multi',\n",
    "    'redundant': 'redun',\n",
    "    'necessary': 'necces',\n",
    "    'comparison': 'compar',\n",
    "    'negated': 'neg',\n",
    "    'unreachable': 'unreach',\n",
    "    'inappropriate': 'inapp',\n",
    "    'parenthesis': '()',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_and_defect_description(task, defect, items, defects, log, defect_log):\n",
    "    \"\"\"Generate an HTML display for a specific task and defect.\"\"\"\n",
    "    task_row = items.loc[task]\n",
    "    defect_row = defects.loc[defect]\n",
    "    submissions = log[(log[\"item\"] == task) & (defect_log[defect])]\n",
    "    \n",
    "    return f\"\"\"\n",
    "    <div style=\"display: flex; justify-content: space-between; gap: 20px;\">\n",
    "        \n",
    "        <div style=\"width: 48%; border: 1px solid #ccc; padding: 10px; border-radius: 5px;\">\n",
    "            <h3>{task_row[\"name\"]}</h3>\n",
    "            <div><strong>Instructions:</strong><br>{task_row[\"instructions\"]}</div>\n",
    "            <div><strong>Solution:</strong><br>\n",
    "                <pre style=\"background-color: #2e2e2e; color: #f5f5f5; padding: 10px; border-radius: 5px; font-family: monospace;\">{task_row[\"solution\"]}</pre>\n",
    "            </div>\n",
    "        </div>\n",
    "        \n",
    "        \n",
    "        <div style=\"width: 48%; border: 1px solid #ccc; padding: 10px; border-radius: 5px;\">\n",
    "            <h3>{defect_row[\"defect name\"]}</h3>\n",
    "            <div><strong>Defect Type:</strong> {defect_row[\"defect type\"]}</div>\n",
    "            <div><strong>Severity:</strong> {defect_row[\"severity\"]}</div>\n",
    "            <div><strong>Description:</strong><br>{defect_row[\"description\"]}</div>\n",
    "            \n",
    "            <div style=\"display: flex; justify-content: space-between; margin-top: 20px;\">\n",
    "                <div style=\"width: 48%; padding: 10px;\">\n",
    "                    <strong>Code Example:</strong><br>\n",
    "                    <pre style=\"background-color: #2e2e2e; color: #f5f5f5; padding: 10px; border-radius: 5px; font-family: monospace;\">{defect_row[\"code example\"]}</pre>\n",
    "                </div>\n",
    "                <div style=\"width: 48%; padding: 10px;\">\n",
    "                    <strong>Code Fix Example:</strong><br>\n",
    "                    <pre style=\"background-color: #2e2e2e; color: #f5f5f5; padding: 10px; border-radius: 5px; font-family: monospace;\">{defect_row[\"code fix example\"]}</pre>\n",
    "                </div>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "    \n",
    "    \n",
    "    <div style=\"border: 1px solid #ccc; padding: 10px; margin-top: 20px; border-radius: 5px;\">\n",
    "        <strong>Example Submission:</strong><br>\n",
    "        <pre style=\"background-color: #2e2e2e; color: #f5f5f5; padding: 10px; border-radius: 5px; font-family: monospace;\">{submissions[\"answer\"].iloc[random.randint(0, len(submissions) - 1)] if len(submissions) else 'No submissions found'}</pre>\n",
    "    </div>\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = pd.read_csv(DATASET_PATH / f'items_{VERSION}.csv', index_col=0)\n",
    "log = pd.read_csv(DATASET_PATH / f'log_{VERSION}.csv', index_col=0, parse_dates=['time'])\n",
    "defects = pd.read_csv(DATASET_PATH / f'defects_{VERSION}.csv', index_col=0)\n",
    "defect_log = pd.read_csv(DATASET_PATH / f'defect_log_{VERSION}.csv', index_col=0)\n",
    "defect_log.columns = defect_log.columns.astype(int)\n",
    "code_to_defect_id = json.load(open(DATASET_PATH / f'code_to_defect_id_{VERSION}.json', \"r\"))\n",
    "defect_presence = defect_log > 0\n",
    "defects['display name'] = defects['defect name'].apply(lambda x: abbreviate_and_truncate_text(x, ordered_abbreviations))\n",
    "items['display name'] = items['name'].apply(truncate_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# Task filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task-defect pairs without minimal support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insufficient_support = defect_presence.groupby(log[\"item\"]).sum() < MIN_TASK_DEFECT_SUBMISSIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# Task-Context Heuristics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rare Task-Defect Pairs\n",
    "\n",
    "Based on the relative frequency of a defect appearing in a given task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaskRarityPrioritizer(DummyTaskPrioritizer):\n",
    "    \"\"\"Prioritizes defects based on how rare they are for a specific task.\"\"\"\n",
    "\n",
    "    def train(self, log, defect_log, defects, items):\n",
    "        \"\"\"Train the model.\"\"\"\n",
    "        super().train(log, defect_log, defects, items)\n",
    "        \n",
    "        defect_log = defect_log > 0\n",
    "        self.task_weights = defect_log.groupby(log[\"item\"]).mean()\n",
    "        self.task_weights = 1 - self.task_weights.loc[items.index, defects.index]\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_rarity_prioritizer = TaskRarityPrioritizer().train(log, defect_log, defects, items)\n",
    "task_rarity_prioritizer.save(OUTPUT_PATH / f'task_rarity_prioritizer_{VERSION}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rarity_values = task_rarity_prioritizer.task_weights.values.flatten()\n",
    "rarity_values = rarity_values[rarity_values < 1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8), layout=\"constrained\")\n",
    "sns.histplot(data=rarity_values, bins=80, shrink=0.8, ax=ax)\n",
    "\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('Rarity (1 - Task-Relative Defect Frequency)')\n",
    "ax.set_ylabel('Frequency (Log Scale)')\n",
    "ax.set_title('Distribution of Task-Defect Rarity (Inverse Task-Relative Defect Frequency)')\n",
    "\n",
    "plt.savefig(IMAGE_DIR / 'task-defect_rarity_distribution.png', dpi=RESOLUTION)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surprising/Characteristic Task-Defect Pairs\n",
    "\n",
    "Based on the z-score of a task-defect pair's frequency compared to the overall defect frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaskCharacteristicPrioritizer(DummyTaskPrioritizer):\n",
    "    \"\"\"Prioritizes defects based on how characteristic they are for a specific task.\"\"\"\n",
    "\n",
    "    def train(self, log, defect_log, defects, items):\n",
    "        \"\"\"Train the model.\"\"\"\n",
    "        super().train(log, defect_log, defects, items)\n",
    "        \n",
    "        defect_log = defect_log > 0\n",
    "        self.task_weights = (defect_log.groupby(log['item']).mean() - defect_log.mean()) / defect_log.std()\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_characteristic_prioritizer = TaskCharacteristicPrioritizer().train(log, defect_log, defects, items)\n",
    "task_characteristic_prioritizer.save(OUTPUT_PATH / f'task_characteristic_prioritizer_{VERSION}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_defect_z_scores = task_characteristic_prioritizer.task_weights\n",
    "z_score_values = pd.Series(task_defect_z_scores.values.flatten()).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_z_scores = task_defect_z_scores.copy()\n",
    "masked_z_scores[insufficient_support] = None\n",
    "\n",
    "defect_names = defects['display name'].loc[task_defect_z_scores.columns]\n",
    "task_names = items['display name'].loc[task_defect_z_scores.index]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 17), layout=\"constrained\")\n",
    "\n",
    "lim = max(abs(z_score_values.max()), abs(z_score_values.min()))\n",
    "\n",
    "sns.heatmap(masked_z_scores, xticklabels=defect_names, yticklabels=task_names, cbar=True, cmap='coolwarm', vmin=-lim, vmax=lim)\n",
    "ax.tick_params(axis='x', labelsize=7)\n",
    "ax.tick_params(axis='y', labelsize=8)\n",
    "plt.title('Characteristic Task-Defect Pairs (Z-Scores of Task-Relative Defect Frequencies with Minimum Support)')\n",
    "plt.xlabel(\"Defects\")\n",
    "plt.ylabel(\"Tasks\")\n",
    "\n",
    "plt.savefig(IMAGE_DIR / 'task-defect_characteristic_heatmap.png', dpi=RESOLUTION)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6), layout=\"constrained\")\n",
    "plt.hist(z_score_values, bins=100, color='skyblue', edgecolor='black')\n",
    "\n",
    "plt.title('Distribution Task-Defect Pair Characteristic Scores (Z-Scores of Task-Relative Defect Frequencies)')\n",
    "plt.xlabel('Z-Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.savefig(IMAGE_DIR / 'task-defect_characteristic_distribution.png', dpi=RESOLUTION)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Currently Taught Topic\n",
    "\n",
    "An LLM-based heuristic on whether a defect is related to a topic currently being taught."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CurrentlyTaughtPrioritizer(DummyTaskPrioritizer):\n",
    "    \"\"\"Prioritizes defects based on LLM judgements on where they relate to the currently taught concepts.\"\"\"\n",
    "\n",
    "    def __init__(self, data_path: Path | str, *args, **kwargs):\n",
    "        \"\"\"Initialize the model.\n",
    "\n",
    "        Keyword Arguments:\n",
    "            data_path -- Path to the LLM judgements.\n",
    "        \"\"\"\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.data = pd.read_csv(data_path, sep='|', index_col=False)\n",
    "\n",
    "    def train(self, log, defect_log, defects, items):\n",
    "        \"\"\"Train the model.\"\"\"\n",
    "        super().train(log, defect_log, defects, items)\n",
    "\n",
    "        task_name_to_id = items.reset_index().set_index('name')['id']\n",
    "        self.data['Task ID'] = self.data['Task Name'].map(task_name_to_id)\n",
    "\n",
    "        self.task_weights = pd.crosstab(self.data['Task ID'], self.data['Defect ID']).astype(bool).astype(int)\n",
    "        self.task_weights = self.task_weights.reindex(index=items.index, columns=defects.index, fill_value=0)\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "currently_taught_prioritizer = CurrentlyTaughtPrioritizer('data/currently_taught.txt').train(log, defect_log, defects, items)\n",
    "currently_taught_prioritizer.save(OUTPUT_PATH / f'currently_taught_prioritizer_{VERSION}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "currently_taught = currently_taught_prioritizer.task_weights\n",
    "\n",
    "defect_names = defects['display name'].loc[currently_taught.columns]\n",
    "task_names = items['display name'].loc[currently_taught.index]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 17), layout=\"constrained\")\n",
    "\n",
    "sns.heatmap(currently_taught, xticklabels=defect_names, yticklabels=task_names)\n",
    "\n",
    "ax.tick_params(axis='x', labelsize=7)\n",
    "ax.tick_params(axis='y', labelsize=8)\n",
    "plt.title('Defects Related to Concepts Currently Taught in the Task')\n",
    "plt.xlabel(\"Defects\")\n",
    "plt.ylabel(\"Tasks\")\n",
    "\n",
    "plt.savefig(IMAGE_DIR / 'task-defect_currently_taught.png', dpi=RESOLUTION)\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# Student-Context Heuristics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student-Specific Frequency (Accuracy)\n",
    "\n",
    "Calculates the accuracy of each student on each defect over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = log.merge(defect_log, left_index=True, right_index=True)\n",
    "df[\"time\"] = pd.to_datetime(df[\"time\"])\n",
    "df = df.sort_values(by=['user', 'time'])\n",
    "accuracy_log = []\n",
    "\n",
    "for user_id, history in tqdm(df.groupby('user')):\n",
    "    correct_count = {defect: 0 for defect in defect_log.columns}\n",
    "    encounter_count = {defect: 0 for defect in defect_log.columns}\n",
    "    \n",
    "    for i, (idx, row) in enumerate(history.iterrows()):\n",
    "        accuracy_row = {}\n",
    "        task_id = row['item']\n",
    "        is_reasonable_mask = ~rare.loc[task_id]\n",
    "        \n",
    "        for defect in defect_log.columns:\n",
    "            is_reasonable = is_reasonable_mask[defect]\n",
    "            \n",
    "            if row[defect] == 0 and is_reasonable:\n",
    "                correct_count[defect] += 1\n",
    "            \n",
    "            if row[defect] == 1 or is_reasonable:\n",
    "                encounter_count[defect] += 1\n",
    "                if encounter_count[defect] > 0:\n",
    "                    accuracy_row[defect] = correct_count[defect] / encounter_count[defect]\n",
    "                else:\n",
    "                    accuracy_row[defect] = np.nan\n",
    "            else:\n",
    "                accuracy_row[defect] = np.nan\n",
    "\n",
    "        accuracy_row['submission id'] = idx\n",
    "        accuracy_log.append(accuracy_row)\n",
    "\n",
    "accuracy_log = pd.DataFrame(accuracy_log).set_index('submission id')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_specific_frequency = (accuracy_log - accuracy_log.mean()) / accuracy_log.std()\n",
    "values = pd.Series(student_specific_frequency.values.flatten()).dropna().values\n",
    "\n",
    "upper_quantile = 0.90\n",
    "student_upper_threshold = np.quantile(values, upper_quantile)\n",
    "lower_quantile = 0.20\n",
    "student_lower_threshold = np.quantile(values, lower_quantile)\n",
    "\n",
    "plt.figure(figsize=small_figsize, layout=\"constrained\")\n",
    "plt.hist(values, bins=200, edgecolor='black')\n",
    "plt.axvline(student_lower_threshold, color='red', linestyle='--', linewidth=2, label=f'{int(lower_quantile*100)}% threshold')\n",
    "plt.axvline(student_upper_threshold, color='green', linestyle='--', linewidth=2, label=f'{int(upper_quantile*100)}% threshold')\n",
    "plt.title('Distribution of Student-Specific Frequency Z-Scores')\n",
    "plt.xlabel('Z-Score')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "if save:\n",
    "    plt.savefig(IMAGE_DIR / 'student_specific_frequency_histogram.png', dpi=RESOLUTION)\n",
    "plt.show()\n",
    "\n",
    "accuracy_at_least_once = accuracy_log[accuracy_log < 1]\n",
    "\n",
    "plot_histogram(accuracy_at_least_once.values.flatten(), 'Distribution of User-Defect Accuracy', bins=10, save_path='user_defect_accuracy_distribution.png')\n",
    "plot_histogram(accuracy_at_least_once.groupby(log['user']).mean().values.flatten(), 'Distribution of User-Defect Accuracy (User Averages)', bins=10, save_path='user_defect_accuracy_user_averages.png')\n",
    "\n",
    "accuracy_means = accuracy_log.mean().sort_values(ascending=False)\n",
    "plt.figure(figsize=long_figsize, layout=\"constrained\")\n",
    "plt.bar(np.arange(len(accuracy_means)), accuracy_means)\n",
    "plt.title(\"Average Accuracy per Defect\")\n",
    "plt.ylabel(\"Average Accuracy\")\n",
    "plt.xlabel(\"Defect\")\n",
    "plt.xticks(np.arange(len(accuracy_means)), [defects['display name'][idx] for idx in accuracy_means.index], rotation=90)\n",
    "plt.grid(axis='y')\n",
    "if save:\n",
    "    plt.savefig(IMAGE_DIR / 'average_accuracy_per_defect.png', dpi=RESOLUTION)\n",
    "plt.show()\n",
    "\n",
    "has_reasonable = (~unreasonable).sum()\n",
    "has_reasonable = has_reasonable.loc[accuracy_means.index]\n",
    "\n",
    "plt.figure(figsize=(12, 6), layout=\"constrained\")\n",
    "plt.bar(np.arange(len(has_reasonable)), has_reasonable)\n",
    "plt.title(\"Number of Reasonable Opportunities per Defect\")\n",
    "plt.ylabel(\"Number of Tasks\")\n",
    "plt.xlabel(\"Defect\")\n",
    "plt.xticks(np.arange(len(has_reasonable)), [defects['display name'][idx] for idx in has_reasonable.index], rotation=90)\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defect Multiplicity\n",
    "\n",
    "Examines how often a defect appears multiple times in a single submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculation and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiplicity_log = defect_log.copy()\n",
    "multiplicity_log[multiplicity_log > 10] = 10\n",
    "\n",
    "means = multiplicity_log[multiplicity_log > 0].mean().sort_values(ascending=False)\n",
    "plt.figure(figsize=long_figsize, layout=\"constrained\")\n",
    "plt.bar(np.arange(len(means)), means.values)\n",
    "plt.xticks(np.arange(len(means)),[defects['display name'][idx] for idx in means.index], rotation=90)\n",
    "plt.title(f\"Defects by Mean Multiplicity (When Occuring)\")\n",
    "plt.xlabel(\"Defect\")\n",
    "plt.ylabel(\"Mean Multiplicity\")\n",
    "if save:\n",
    "    plt.savefig(IMAGE_DIR / 'defects_by_mean_multiplicity.png', dpi=RESOLUTION)\n",
    "plt.show()\n",
    "\n",
    "vars = multiplicity_log[multiplicity_log > 0].var().sort_values(ascending=False)\n",
    "plt.figure(figsize=small_figsize, layout=\"constrained\")\n",
    "plt.bar(np.arange(len(vars)), vars.values)\n",
    "plt.xticks(np.arange(len(vars)),[defects['display name'][idx] for idx in vars.index], rotation=90)\n",
    "plt.title(f\"Multiplicity Variance\")\n",
    "plt.xlabel(\"Defect\")\n",
    "plt.ylabel(\"Multiplicity Variance\")\n",
    "if save:\n",
    "    plt.savefig(IMAGE_DIR / 'multiplicity_variance.png', dpi=RESOLUTION)\n",
    "plt.show()\n",
    "\n",
    "plot_histogram(multiplicity_log[multiplicity_log > 0].values.flatten(), 'Distribution of Multiplicity', bins=10, save_path='multiplicity_distribution.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student Recently Fixed\n",
    "\n",
    "Examines the recency of a defect being fixed by a student."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "df = log.merge(defect_log, left_index=True, right_index=True)\n",
    "df[\"time\"] = pd.to_datetime(df[\"time\"])\n",
    "df = df.sort_values(by=['user', 'time'])\n",
    "\n",
    "recently_fixed_log = []\n",
    "for user_id, history in tqdm(df.groupby('user')):\n",
    "    last_fixed = {defect: None for defect in defect_log.columns}\n",
    "    for i, (idx, row) in enumerate(history.iterrows()):\n",
    "        recency_row = {}\n",
    "        for defect in defect_log.columns:\n",
    "            if row[defect] == 1:\n",
    "                if np.random.rand() < 0.8:\n",
    "                    recency_row[defect] = 0\n",
    "                    last_fixed[defect] = i\n",
    "                else:\n",
    "                    recency_row[defect] = np.nan\n",
    "            else:\n",
    "                if last_fixed[defect] is not None:\n",
    "                    recency_row[defect] = i - last_fixed[defect]\n",
    "                else:\n",
    "                    recency_row[defect] = np.nan\n",
    "        recency_row['submission id'] = idx\n",
    "        recently_fixed_log.append(recency_row)\n",
    "\n",
    "recently_fixed_log = pd.DataFrame(recently_fixed_log).set_index('submission id')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_time_rate = (recently_fixed_log == 0)[~recently_fixed_log.isna()].mean().sort_values(ascending=True)\n",
    "\n",
    "plt.figure(figsize=long_figsize, layout=\"constrained\")\n",
    "plt.bar(np.arange(len(first_time_rate)), first_time_rate)\n",
    "plt.title(\"Percentage of First-Time Occurrences per Defect\")\n",
    "plt.ylabel(\"First-Time Rate\")\n",
    "plt.xlabel(\"Defect\")\n",
    "plt.xticks(np.arange(len(first_time_rate)), [defects['display name'][idx] for idx in first_time_rate.index], rotation=90)\n",
    "plt.grid(axis='y')\n",
    "if save:\n",
    "    plt.savefig(IMAGE_DIR / 'percentage_of_first_time_occurrences_per_defect.png', dpi=RESOLUTION)\n",
    "plt.show()\n",
    "\n",
    "bins = [0, 1, 2, 4, 9, 14, 19, 24, 29, np.inf]\n",
    "bin_labels = ['1', '2', '3-4', '5-9', '10-14', '15-19', '20-24', '25-29', '30+']\n",
    "recency_binned = recently_fixed_log.apply(lambda col: pd.cut(col, bins=bins, labels=bin_labels))\n",
    "recency_counts = recency_binned.apply(lambda col: col.value_counts()).fillna(0).astype(int)\n",
    "recency_scaled = recency_counts.div(recency_counts.sum(axis=0), axis=1)\n",
    "recency_scaled = recency_scaled.loc[:, first_time_rate.index]\n",
    "\n",
    "plt.figure(figsize=(12, 6), layout=\"constrained\")\n",
    "sns.heatmap(recency_scaled, cmap='viridis', cbar_kws={'label': 'frequency'}, xticklabels=[defects['display name'][idx] for idx in recency_scaled.columns])\n",
    "plt.title(\"Number of Sessions Before Fix Reoccurrence\")\n",
    "plt.xlabel(\"Defect\")\n",
    "plt.ylabel(\"Recency Bin\")\n",
    "plt.gca().invert_yaxis()\n",
    "if save:\n",
    "    plt.savefig(IMAGE_DIR / 'heatmap_of_recency_bins_per_defect.png', dpi=RESOLUTION)\n",
    "plt.show()\n",
    "\n",
    "mean_recency = recently_fixed_log.replace(0, np.nan).median()\n",
    "mean_recency = mean_recency.loc[first_time_rate.index]\n",
    "\n",
    "plt.figure(figsize=long_figsize, layout=\"constrained\")\n",
    "plt.bar(np.arange(len(mean_recency)), mean_recency)\n",
    "plt.title(\"Median Recency (# of Submissions Since Last Seen) per Defect\")\n",
    "plt.ylabel(\"Median Recency\")\n",
    "plt.xlabel(\"Defect\")\n",
    "plt.xticks(np.arange(len(mean_recency)), [defects['display name'][idx] for idx in first_time_rate.index], rotation=90)\n",
    "plt.grid(axis='y')\n",
    "if save:\n",
    "    plt.savefig(IMAGE_DIR / 'average_recency_per_defect.png', dpi=RESOLUTION)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# Baseline Heuristics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Severity\n",
    "\n",
    "Analyzes the severity of defects as a prioritization baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "severity_log = defect_log * defects.loc[defect_log.columns]['severity']\n",
    "severity_log[severity_log.isna()] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_severity = severity_log.copy()\n",
    "df_severity[df_severity == 0] = np.nan\n",
    "means = df_severity.groupby(log['item']).max().mean(axis=1).sort_values()\n",
    "plt.figure(figsize=(13, 4), layout=\"constrained\")\n",
    "plt.bar(np.arange(len(means)), means.values)\n",
    "plt.xticks(np.arange(len(means)), [items['name'][idx].split(' ')[0] for idx in means.index], rotation=90)\n",
    "plt.title(\"Mean Severity for Each Task\")\n",
    "plt.xlabel(\"Task\")\n",
    "plt.ylabel(\"Severity\")\n",
    "plt.tick_params(axis='x', labelsize=7)\n",
    "if save:\n",
    "    plt.savefig(IMAGE_DIR / 'mean_severity.png', dpi=RESOLUTION)\n",
    "plt.show()\n",
    "\n",
    "df = severity_log.copy()\n",
    "df[df == 0] = np.nan\n",
    "differences = df.apply(lambda row: -row.nlargest(2).diff().iloc[-1] if len(row.nlargest(2)) > 1 else np.nan, axis=1).value_counts().sort_index()\n",
    "\n",
    "plt.figure(figsize=small_figsize, layout=\"constrained\")\n",
    "plt.bar(differences.index.astype(int), differences.values, edgecolor='black')\n",
    "plt.title('Histogram of Differences in Severity')\n",
    "plt.xlabel('Difference')\n",
    "plt.ylabel('Count')\n",
    "if save:\n",
    "    plt.savefig(f'images/severity_differences.png', dpi=RESOLUTION)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# Rejected Heuristics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Spent on Task\n",
    "\n",
    "A heuristic based on the time a student spends on a task, with outliers clipped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log['relative_time_spent'] = log['responseTime'] / log.groupby('item')['responseTime'].transform('mean')\n",
    "clip_threshold = 5\n",
    "print(f'Clipping all submissions to {clip_threshold} times the task mean: {(log[\"relative_time_spent\"] > clip_threshold).mean():.2%} changed.')\n",
    "log.loc[log['relative_time_spent'] > clip_threshold, 'relative_time_spent'] = clip_threshold\n",
    "time_spent_threshold = log['relative_time_spent'].quantile(0.90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=small_figsize, layout=\"constrained\")\n",
    "sns.histplot(log['relative_time_spent'], bins=1000, kde=True)\n",
    "plt.axvline(time_spent_threshold, color='red', linestyle='--', label=f'{time_spent_threshold:.2f} (90th Percentile)')\n",
    "plt.title(\"Distribution of Relative Time Spent per Task (Values Over 5 Clipped)\")\n",
    "plt.xlabel(\"Relative Time Spent\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "if save:\n",
    "    plt.savefig(IMAGE_DIR / 'distribution_of_relative_time_spent_per_task.png', dpi=RESOLUTION)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Associated with Poor Performance (Locally)\n",
    "\n",
    "A heuristic based on the precision of a defect in predicting task failures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "_, not_log, _, not_defect_log, _ = loader.load(DATASET_PATH, DATASET_PATH, only_correct=False)\n",
    "df = not_log[['item', 'correct']].merge(not_defect_log, left_index=True, right_index=True)\n",
    "correlations = {}\n",
    "for task_id, task_df in df.groupby('item'):\n",
    "    corr_dict = {}\n",
    "    for defect in defect_log.columns:\n",
    "        defect_presence = task_df[defect]\n",
    "        incorrect = ~task_df['correct']\n",
    "        if defect_presence.nunique() > 1 and incorrect.nunique() > 1:\n",
    "            corr_dict[defect] = precision_score(incorrect, defect_presence)\n",
    "        else:\n",
    "            corr_dict[defect] = np.nan\n",
    "    correlations[task_id] = corr_dict\n",
    "performance = pd.DataFrame.from_dict(correlations, orient='index')\n",
    "performance[unreasonable] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defect_names = defects['display name'].loc[performance.columns]\n",
    "task_names = items['name'].loc[performance.index].apply(lambda x: abbreviate_text(x))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 17), layout=\"constrained\")\n",
    "sns.heatmap(performance, xticklabels=defect_names, yticklabels=task_names, cbar_kws={'label': 'Precision'})\n",
    "ax.tick_params(axis='x', labelsize=7)\n",
    "ax.tick_params(axis='y', labelsize=8)\n",
    "plt.title('Defect-Failure Precision')\n",
    "plt.xlabel(\"Defects\")\n",
    "plt.ylabel(\"Tasks\")\n",
    "if save:\n",
    "    plt.savefig(IMAGE_DIR / 'task-defect_precision_heatmap.png', dpi=RESOLUTION)\n",
    "plt.show()\n",
    "\n",
    "performances = performance.stack().dropna()\n",
    "\n",
    "plt.figure(figsize=small_figsize, layout=\"constrained\")\n",
    "plt.hist(performances, bins=100, color='skyblue', edgecolor='black')\n",
    "plt.title('Histogram of Task-Defect Pair Precision in Predicting Failures')\n",
    "plt.xlabel('Precision')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "if save:\n",
    "    plt.savefig(IMAGE_DIR / 'histogram_of_task-defect_pair_precision.png', dpi=RESOLUTION)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Opportunity Likelihood\n",
    "\n",
    "A heuristic based on the probability of a student encountering a specific defect in a future task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tasks = items.index\n",
    "opportunity_log = []\n",
    "df = log.merge(defect_log, left_index=True, right_index=True)\n",
    "df[\"time\"] = pd.to_datetime(df[\"time\"])\n",
    "df = df.sort_values(by=['user', 'time'])\n",
    "\n",
    "for user_id, history in tqdm(df.groupby('user')):\n",
    "    completed_tasks = set()\n",
    "    for submission_id, row in history.iterrows():\n",
    "        completed_tasks.add(row['item'])\n",
    "        remaining_tasks = [t for t in all_tasks if t not in completed_tasks]\n",
    "        if not remaining_tasks:\n",
    "            opportunity_log.append({'submission id': submission_id, **{defect: 0.0 for defect in relative_frequencies.columns}})\n",
    "            continue\n",
    "        \n",
    "        weights = np.array([2.0 if t > row['item'] else 1.0 for t in remaining_tasks])\n",
    "        weighted_avg = (relative_frequencies.loc[remaining_tasks].T @ weights) / weights.sum()\n",
    "        opportunity_log.append({'submission id': submission_id, **weighted_avg.to_dict()})\n",
    "\n",
    "opportunity_log = pd.DataFrame(opportunity_log).set_index('submission id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(opportunity_log.values.flatten(), 'Histogram of Future Opportunities', save_path='histogram_of_future_opportunities.png')\n",
    "\n",
    "means = opportunity_log.mean().sort_values(ascending=False)\n",
    "plt.figure(figsize=long_figsize, layout=\"constrained\")\n",
    "bar_width = 0.4\n",
    "ticks = np.arange(len(means)) + 0.4\n",
    "\n",
    "plt.bar(ticks - bar_width / 2, means.values, label='Opportunity', width=bar_width)\n",
    "plt.bar(ticks + bar_width / 2, defect_log[means.index].mean().values, label='Frequency', width=bar_width)\n",
    "\n",
    "plt.xticks(ticks,[defects['display name'][idx] for idx in means.index], rotation=90)\n",
    "plt.title(f\"Defects by Mean Opportunity vs Frequency\")\n",
    "plt.xlabel(\"Defect\")\n",
    "plt.ylabel(\"Mean Opportunity\")\n",
    "plt.legend()\n",
    "if save:\n",
    "    plt.savefig(IMAGE_DIR / 'defects_by_mean_opportunity.png', dpi=RESOLUTION)\n",
    "plt.show()\n",
    "\n",
    "task_opportunities = opportunity_log.groupby(log['item']).mean()\n",
    "task_opportunities = (task_opportunities - task_opportunities.mean(axis=0))\n",
    "\n",
    "defect_names = defects['display name'].loc[task_opportunities.columns]\n",
    "task_names = items['name'].loc[task_opportunities.index].apply(lambda x: abbreviate_text(x))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 17), layout=\"constrained\")\n",
    "sns.heatmap(task_opportunities, xticklabels=defect_names, yticklabels=task_names, cmap='coolwarm', cbar_kws={'label': 'Z-Score'}) # assuming similar scale as z-score heatmap\n",
    "ax.tick_params(axis='x', labelsize=7)\n",
    "ax.tick_params(axis='y', labelsize=8)\n",
    "plt.title('Future Opportunity Z-Score by Task-Defect Pair')\n",
    "plt.xlabel(\"Defects\")\n",
    "plt.ylabel(\"Tasks\")\n",
    "if save:\n",
    "    plt.savefig(IMAGE_DIR / 'task-defect_opportunity_heatmap.png', dpi=RESOLUTION)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
