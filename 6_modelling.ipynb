{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up and global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.prioritization import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CONFIG_ENV\"] = \"debug\"\n",
    "\n",
    "from config import load_config\n",
    "config = load_config()\n",
    "\n",
    "RESOLUTION = config['DEFAULTS']['resolution']\n",
    "SEED = config['DEFAULTS']['random_seed']\n",
    "\n",
    "# input data\n",
    "BENCHMARK_PATH = config['PATHS']['benchmark_dataset']\n",
    "STORAGE_PATH = config['PATHS']['storage']\n",
    "\n",
    "# output data\n",
    "IMAGE_DIR = config['PATHS']['images']\n",
    "\n",
    "os.makedirs(IMAGE_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = pd.read_csv(STORAGE_PATH / 'items.csv', index_col=0)\n",
    "defects = pd.read_csv(STORAGE_PATH / f'defects.csv', index_col=0)\n",
    "\n",
    "df = pd.read_csv(BENCHMARK_PATH / 'benchmark_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_discrete_features = [col for col in df.columns if col.endswith('(Left Discrete)')]\n",
    "right_discrete_features = [col for col in df.columns if col.endswith('(Right Discrete)')]\n",
    "left_continuous_features = [col for col in df.columns if col.endswith('(Left Continuous)')]\n",
    "right_continuous_features = [col for col in df.columns if col.endswith('(Right Continuous)')]\n",
    "\n",
    "if any(map(lambda x: len(x) == 0, [left_discrete_features, right_discrete_features, left_continuous_features, right_continuous_features])):\n",
    "    raise ValueError('Some of the feature sets are empty')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difference features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "X = df[left_discrete_features + right_discrete_features]\n",
    "y = df['left won']\n",
    "\n",
    "# convert into binary itemsets\n",
    "itemsets = X.apply(lambda x: [f\"{col}>\" if x[col] > 0 else f\"{col}<=\" for col in X.columns], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(itemsets).transform(itemsets)\n",
    "encoded = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "encoded['winner'] = y.values.astype(bool)\n",
    "\n",
    "# run apriori\n",
    "frequent_itemsets = apriori(encoded, min_support=0.1, use_colnames=True)\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.6)\n",
    "\n",
    "# filter rules\n",
    "# predicting the output variable\n",
    "rules = rules[rules['consequents'].apply(lambda x: 'winner' in x)]\n",
    "# sufficient confidence and support\n",
    "rules = rules[\n",
    "    (rules['confidence'] > 0.7) & \n",
    "    (rules['support'] > 0.15)\n",
    "]\n",
    "# sort\n",
    "rules = rules.sort_values(by='lift', ascending=False)\n",
    "# only one rule per antecedent\n",
    "rules = rules.drop_duplicates(subset=['antecedents'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature groups and combined dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***\n",
    "# Step 4: Combine all engineered features into final dataframe\n",
    "# ***\n",
    "\n",
    "engineered_df = pd.concat([\n",
    "    left_discrete_features,\n",
    "    right_discrete_features,\n",
    "    discrete_diff_features,\n",
    "    left_continuous,\n",
    "    right_continuous,\n",
    "    continuous_diff,\n",
    "    derived_df,\n",
    "    interaction_df\n",
    "], axis=1)\n",
    "\n",
    "print(\"Final engineered dataframe shape:\", engineered_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_groups = {\n",
    "    \"Left Discrete\": left_discrete_features.columns.tolist(),\n",
    "    \"Right Discrete\": right_discrete_features.columns.tolist(),\n",
    "    \"Discrete Diff\": discrete_diff_features.columns.tolist(),\n",
    "    \"Left+Right Continuous\": left_continuous.columns.tolist() + right_continuous.columns.tolist(),\n",
    "    \"Continuous Diff\": continuous_diff.columns.tolist(),\n",
    "    \"Derived Rules\": derived_df.columns.tolist(),\n",
    "    \"Interactions\": interaction_df.columns.tolist(),\n",
    "    \"All Features\": engineered_df.columns.tolist()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# Cross-validation folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***\n",
    "# Prepare target and folds\n",
    "# ***\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# target\n",
    "y = df['left won']\n",
    "\n",
    "# define KFold\n",
    "NUM_FOLDS = 5\n",
    "kf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "# ***\n",
    "# Prepare a place to store results\n",
    "# ***\n",
    "\n",
    "results = []\n",
    "\n",
    "# will keep fold-level predictions\n",
    "fold_predictions = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***\n",
    "# Ablation loop (Option A: retrain per fold per group)\n",
    "# ***\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(kf.split(df)):\n",
    "    print(f\"\\n=== Fold {fold_idx+1}/{NUM_FOLDS} ===\")\n",
    "    \n",
    "    X_train_full = df.iloc[train_idx]\n",
    "    X_test_full = df.iloc[test_idx]\n",
    "    y_train = y.iloc[train_idx]\n",
    "    y_test = y.iloc[test_idx]\n",
    "    \n",
    "    for group_name, cols in feature_groups.items():\n",
    "        print(f\"Training ablation group: {group_name}\")\n",
    "        \n",
    "        X_train = X_train_full[cols]\n",
    "        X_test = X_test_full[cols]\n",
    "        \n",
    "        # Example model; could swap with Logistic, Tree, etc.\n",
    "        model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        y_proba = model.predict_proba(X_test)[:,1]\n",
    "        \n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        auc = roc_auc_score(y_test, y_proba)\n",
    "        \n",
    "        results.append({\n",
    "            \"fold\": fold_idx,\n",
    "            \"group\": group_name,\n",
    "            \"accuracy\": acc,\n",
    "            \"auc\": auc\n",
    "        })\n",
    "        \n",
    "        # Save predictions for later analysis if needed\n",
    "        fold_predictions[(fold_idx, group_name)] = pd.DataFrame({\n",
    "            \"y_true\": y_test.values,\n",
    "            \"y_pred\": y_pred,\n",
    "            \"y_proba\": y_proba\n",
    "        }, index=y_test.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***\n",
    "# Aggregate results\n",
    "# ***\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "display(results_df.groupby(\"group\")[[\"accuracy\",\"auc\"]].agg([\"mean\",\"std\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***\n",
    "# Plot results\n",
    "# ***\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(data=results_df, x='group', y='accuracy', ci='sd')\n",
    "plt.title(\"Ablation Study: Accuracy by Feature Group\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Feature Group\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(data=results_df, x='group', y='auc', ci='sd')\n",
    "plt.title(\"Ablation Study: AUC by Feature Group\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.xlabel(\"Feature Group\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***\n",
    "# Optional: Inspect feature importances per group (for interpretability)\n",
    "# ***\n",
    "\n",
    "for group_name, cols in feature_groups.items():\n",
    "    print(f\"\\n=== Feature importances: {group_name} ===\")\n",
    "    \n",
    "    # retrain on full dataset for interpretability\n",
    "    X_full = df[cols]\n",
    "    model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
    "    model.fit(X_full, y)\n",
    "    \n",
    "    importances = pd.DataFrame({\n",
    "        \"feature\": cols,\n",
    "        \"importance\": model.feature_importances_\n",
    "    }).sort_values(\"importance\", ascending=False)\n",
    "    \n",
    "    display(importances.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***\n",
    "# Optional: Save fold predictions and aggregated results\n",
    "# ***\n",
    "\n",
    "OUTPUT_DIR = DATASET_PATH / \"ablation_results\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "results_df.to_csv(OUTPUT_DIR / \"ablation_summary.csv\", index=False)\n",
    "\n",
    "for key, df_pred in fold_predictions.items():\n",
    "    fold_idx, group_name = key\n",
    "    df_pred.to_csv(OUTPUT_DIR / f\"fold{fold_idx}_{group_name.replace(' ','_')}_predictions.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
