{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up and global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "from IPython.display import display, HTML\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "import src.ipython_loader as loader\n",
    "\n",
    "from src.prioritization import *\n",
    "from src.utils import split_data_by_users, gini\n",
    "\n",
    "RESOLUTION = 300\n",
    "VERSION = '0.0.0'\n",
    "DATASET_PATH = Path('data') / 'datasets' / f'ipython_{VERSION}'\n",
    "OUTPUT_PATH = DATASET_PATH / 'heuristics'\n",
    "BINARY_CMAP = ListedColormap(['red', 'green'])\n",
    "\n",
    "IMAGE_DIR = Path('images') / \"heuristics\"\n",
    "\n",
    "CACHE_PATH = Path('data') / 'cache'\n",
    "\n",
    "os.makedirs(CACHE_PATH, exist_ok=True)\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "os.makedirs(IMAGE_DIR, exist_ok=True)\n",
    "\n",
    "MIN_TASK_DEFECT_SUBMISSIONS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = pd.read_csv(DATASET_PATH / f'items_{VERSION}.csv', index_col=0)\n",
    "log = pd.read_csv(DATASET_PATH / f'log_{VERSION}.csv', index_col=0, parse_dates=['time'])\n",
    "defects = pd.read_csv(DATASET_PATH / f'defects_{VERSION}.csv', index_col=0)\n",
    "defect_log = pd.read_csv(DATASET_PATH / f'defect_log_{VERSION}.csv', index_col=0)\n",
    "defect_log.columns = defect_log.columns.astype(int)\n",
    "code_to_defect_id = json.load(open(DATASET_PATH / f'code_to_defect_id_{VERSION}.json', \"r\"))\n",
    "defect_presence = defect_log > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_log, test_log, train_defect_log, test_defect_log = split_data_by_users(log, defect_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_defects = test_defect_log > 0\n",
    "print(\"Fraction of Submissions with Multiple Defects:\", (test_defects.sum(axis=1) > 1).mean())\n",
    "print(\"Total Number\", (test_defects.sum(axis=1) > 1).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# Heuristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = items, defects\n",
    "\n",
    "models = {\n",
    "    \"Task Common\": TaskCommonModel(*data),\n",
    "    \"Task Characteristic\": TaskCharacteristicModel(*data),\n",
    "    \"Student Frequency\": StudentFrequencyModel(*data),\n",
    "    \"Student Characteristic\": StudentCharacteristicModel(*data),\n",
    "    \"Student Encountered\": StudentEncounteredBeforeModel(*data),\n",
    "    \"Defect Multiplicity\": DefectMultiplicityModel(*data),\n",
    "    \"Severity Baseline\": SeverityModel(*data),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in (pbar :=tqdm(models.items(), desc=\"Training Models\")):\n",
    "    pbar.set_description(f\"Training {name}\")\n",
    "    model.update(train_log, train_defect_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# Pilot testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Written with ChatGPT\n",
    "\n",
    "def _get_prioritized_defects(submission, defect_counts, active_models: dict, defects: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Generate a DataFrame of prioritized defects for a single submission.\n",
    "\n",
    "    Run all active models on a single submission and return a DataFrame of \n",
    "    defects ranked by consensus score, including the original scores.\n",
    "    \"\"\"\n",
    "    present_defects = defect_counts[defect_counts > 0]\n",
    "    all_defect_scores = pd.DataFrame(index=present_defects.index)\n",
    "    \n",
    "    if present_defects.empty:\n",
    "        return all_defect_scores\n",
    "\n",
    "    for name, model in active_models.items():\n",
    "        scores = model.prioritize(submission, defect_counts)\n",
    "        # Store the priority score for display\n",
    "        all_defect_scores[name] = scores.loc[present_defects.index]\n",
    "    \n",
    "    # Calculate rank for sorting (sum of ranks across all models for visualization)\n",
    "    all_defect_scores['SUM_RANK'] = all_defect_scores.rank(ascending=False).sum(axis=1)\n",
    "    \n",
    "    # Sort by consensus rank (lower sum rank = higher consensus priority)\n",
    "    sorted_defects_df = all_defect_scores.sort_values(by='SUM_RANK', ascending=True)\n",
    "    return sorted_defects_df\n",
    "\n",
    "def _generate_submission_html(sub_num: int, submission: pd.Series, sorted_defects_df: pd.DataFrame, active_models: dict, items: pd.DataFrame, defects: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Generate HTML description of a single submission.\n",
    "    \n",
    "    This includes the submission number, task info, submitted code, and the defects table with\n",
    "    colored prioritization scores.\n",
    "    \"\"\"\n",
    "    task_id = submission['item']\n",
    "    task_row = items.loc[task_id]\n",
    "    present_defects_count = len(sorted_defects_df)\n",
    "    \n",
    "    html_output = f\"\"\"\n",
    "    <style>\n",
    "        .defect-tooltip {{\n",
    "            position: relative;\n",
    "            display: inline-block;\n",
    "            cursor: help;\n",
    "            border-bottom: 1px dashed #fff; /* Use light dash for dark background */\n",
    "        }}\n",
    "        .defect-tooltip .tooltiptext {{\n",
    "            visibility: hidden;\n",
    "            width: 400px;\n",
    "            background-color: #1e1e1e; /* Deeper dark background */\n",
    "            color: #f5f5f5; /* Light text color */\n",
    "            text-align: left;\n",
    "            border-radius: 6px;\n",
    "            padding: 10px;\n",
    "            position: absolute;\n",
    "            z-index: 1000;\n",
    "            /* FIX 4: Adjusted tooltip position to right/center */\n",
    "            top: 50%;\n",
    "            left: 100%; \n",
    "            transform: translateY(-50%) translateX(10px); /* Center vertically, move right 10px */\n",
    "            opacity: 0;\n",
    "            transition: opacity 0.3s;\n",
    "            font-family: monospace;\n",
    "            white-space: normal;\n",
    "            box-shadow: 0 4px 8px rgba(0,0,0,0.5);\n",
    "        }}\n",
    "        .defect-tooltip:hover .tooltiptext {{\n",
    "            visibility: visible;\n",
    "            opacity: 1;\n",
    "        }}\n",
    "        .tooltiptext strong {{\n",
    "            color: #FFD700;\n",
    "        }}\n",
    "        .tooltiptext pre {{\n",
    "            background-color: #333; /* Darker pre background */\n",
    "            padding: 5px;\n",
    "            border-radius: 3px;\n",
    "            overflow-x: auto;\n",
    "        }}\n",
    "        /* FIX 2: Dark Mode for Instructions Panel (Increased Contrast) */\n",
    "        .instructions-panel {{\n",
    "            background-color: #333 !important; /* Darker background */\n",
    "            color: #f5f5f5 !important; /* Light text color */\n",
    "            border: 1px solid #555 !important;\n",
    "        }}\n",
    "        /* FIX 3: Dark Mode for Table Headers (Increased Contrast) */\n",
    "        .defect-table-header {{\n",
    "            background-color: #444 !important; /* Clearly dark background */\n",
    "            color: #f5f5f5 !important; /* Light text color */\n",
    "        }}\n",
    "        /* FIX 5: Dark Mode for Table Body Cells */\n",
    "        .data-cell {{\n",
    "            border: 1px solid #555;\n",
    "            padding: 8px;\n",
    "            text-align: center;\n",
    "            background-color: #333; /* Dark background */\n",
    "            color: #f5f5f5; /* Light text */\n",
    "        }}\n",
    "        .data-cell-left {{\n",
    "            border: 1px solid #555;\n",
    "            padding: 8px;\n",
    "            text-align: left;\n",
    "            background-color: #333;\n",
    "            color: #f5f5f5;\n",
    "            font-weight: bold;\n",
    "        }}\n",
    "    </style>\n",
    "    <div style=\"border: 2px solid #555; margin: 20px 0; padding: 15px; border-radius: 8px; background-color: #222; color: #f5f5f5;\">\n",
    "        <div style=\"background-color: #4CAF50; color: white; padding: 8px; border-radius: 5px; margin-bottom: 15px;\">\n",
    "            <h3 style=\"margin: 0;\">SUBMISSION {sub_num + 1} | Task ID: {task_id} ({task_row['display name']})</h3>\n",
    "            <p style=\"margin: 0; font-size: 0.9em;\">Submitted at: {submission['time']}</p>\n",
    "        </div>\n",
    "        \n",
    "        <!-- Task and Submission Content -->\n",
    "        <div style=\"display: flex; gap: 15px; margin-bottom: 15px;\">\n",
    "            <div class=\"instructions-panel\" style=\"flex: 1; padding: 10px; border-radius: 5px;\">\n",
    "                <strong>Instructions:</strong>\n",
    "                <p style=\"font-size: 0.9em; max-height: 100px; overflow-y: auto;\">{task_row['instructions']}</p>\n",
    "            </div>\n",
    "            <div style=\"flex: 1.5; border: 1px solid #ddd; padding: 10px; border-radius: 5px; background-color: #2e2e2e; color: #f5f5f5; font-family: monospace;\">\n",
    "                <strong>Submitted Code:</strong>\n",
    "                <pre style=\"margin: 0; max-height: 150px; overflow-y: auto; white-space: pre-wrap;\">{submission['answer']}</pre>\n",
    "            </div>\n",
    "        </div>\n",
    "\n",
    "        <!-- Defect Prioritization Table -->\n",
    "        <h4 style=\"margin-top: 20px;\">Prioritized Defects (Defects Present: {present_defects_count})</h4>\n",
    "        <table style=\"width: 100%; border-collapse: collapse; font-size: 0.9em;\">\n",
    "            <thead>\n",
    "                <tr class=\"defect-table-header\">\n",
    "                    <th style=\"border: 1px solid #555; padding: 8px; width: 30%; text-align: left;\">Defect (Hover for Details)</th>\n",
    "    \"\"\"\n",
    "    \n",
    "    # Add a column header for each model\n",
    "    for name in active_models.keys():\n",
    "        html_output += f\"<th style=\\\"border: 1px solid #555; padding: 8px; width: 12%;\\\">{name}<br>({active_models[name].get_measure_name()})</th>\"\n",
    "    \n",
    "    html_output += \"</tr></thead><tbody>\"\n",
    "    \n",
    "    # --- 5. Generate Table Rows ---\n",
    "    for defect_id in sorted_defects_df.index:\n",
    "        defect_row = defects.loc[defect_id]        \n",
    "        # --- Tooltip Content Generation (Sanitized HTML) ---\n",
    "        \n",
    "        # Start with required content\n",
    "        tooltip_content = f\"\"\"\n",
    "        <strong>Type:</strong> {defect_row['defect type']}<br>\n",
    "        <strong>Description:</strong> {defect_row['description']}<br>\n",
    "        \"\"\"\n",
    "        \n",
    "        # Helper to conditionally add code blocks\n",
    "        def add_code_block(title, key, content):\n",
    "            if pd.isna(content) or content == \"\":\n",
    "                return \"\"\n",
    "            escaped_content = content.replace('<', '&lt;').replace('>', '&gt;')\n",
    "            return f\"\"\"\n",
    "            <strong>{title}:</strong> <pre>{escaped_content}</pre>\n",
    "            \"\"\"\n",
    "\n",
    "        # Conditionally add Example Code\n",
    "        tooltip_content += add_code_block(\n",
    "            \"Example Code\", \n",
    "            'code example', \n",
    "            defect_row['code example']\n",
    "        )\n",
    "\n",
    "        # Conditionally add Suggested Fix\n",
    "        tooltip_content += add_code_block(\n",
    "            \"Suggested Fix\", \n",
    "            'code fix example', \n",
    "            defect_row['code fix example']\n",
    "        )\n",
    "        \n",
    "        html_output += \"<tr>\"\n",
    "        \n",
    "        # Defect Name with Tooltip\n",
    "        html_output += f\"\"\"\n",
    "        <td class=\"data-cell-left\">\n",
    "            <div class=\"defect-tooltip\">{defect_row['display name']}\n",
    "                <span class=\"tooltiptext\">{tooltip_content}</span>\n",
    "            </div>\n",
    "        </td>\n",
    "        \"\"\"        \n",
    "        # Model Scores\n",
    "        for name in active_models.keys():\n",
    "            score = sorted_defects_df.loc[defect_id, name]\n",
    "            \n",
    "            # --- Score Visualization (Color Highlighting) ---\n",
    "            min_score = sorted_defects_df[name].min()\n",
    "            max_score = sorted_defects_df[name].max()\n",
    "            \n",
    "            if max_score == min_score:\n",
    "                normalized_score = 0.5 # Neutral color if all scores are identical\n",
    "            else:\n",
    "                # Map score from [min, max] to a visual intensity range [0.3, 1.0]\n",
    "                normalized_score = np.interp(score, [min_score, max_score], [0.3, 1.0])\n",
    "            \n",
    "            # Create a reddish hue where intensity reflects score\n",
    "            r = 255\n",
    "            g = b = 255 - int(200 * normalized_score)\n",
    "            g = max(0, g)\n",
    "            b = max(0, b)\n",
    "            \n",
    "            color = f\"rgb({r}, {g}, {b})\"\n",
    "\n",
    "            html_output += f\"<td class=\\\"data-cell\\\" style=\\\"background-color: {color};\\\">{score:.3f}</td>\"\n",
    "        \n",
    "        html_output += \"</tr>\"\n",
    "    \n",
    "    html_output += \"</tbody></table>\"\n",
    "    html_output += \"</div>\"\n",
    "    return html_output\n",
    "\n",
    "\n",
    "def pilot_test_user(user_id: int, models: dict, log: pd.DataFrame, defect_log: pd.DataFrame, items: pd.DataFrame, defects: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Analyze a single user's submission history chronologically.\n",
    "\n",
    "    Args:\n",
    "        user_id: The ID of the student to analyze.\n",
    "        models: Dictionary of model instances to test.\n",
    "        log: Full log DataFrame (for user filtering).\n",
    "        defect_log: Full defect matrix.\n",
    "        items: Full items/tasks DataFrame.\n",
    "        defects: Full defects DataFrame.\n",
    "    \"\"\"\n",
    "    # --- 1. Prepare User Data ---\n",
    "    user_log = log[log['user'] == user_id].sort_values('time')\n",
    "    user_defect_log = defect_log.loc[user_log.index]\n",
    "    \n",
    "    if user_log.empty:\n",
    "        display(HTML(f\"<h2>No submissions found for User ID: {user_id}</h2>\"))\n",
    "        return\n",
    "    \n",
    "    print(f\"--- STARTING PILOT TEST FOR USER: {user_id} ---\")\n",
    "\n",
    "    # create temporary models to avoid modifying the original\n",
    "    temp_models = deepcopy(models)\n",
    "    \n",
    "    # --- 2. Iterate Through Submissions Chronologically ---\n",
    "    for sub_num, (index, submission) in enumerate(tqdm(user_log.iterrows(), total=len(user_log), desc=f\"User {user_id} Submissions\")):\n",
    "        defect_counts = user_defect_log.loc[index]\n",
    "        \n",
    "        # --- Prioritization and Ranking ---\n",
    "        sorted_defects_df = _get_prioritized_defects(submission, defect_counts, temp_models, defects)\n",
    "        \n",
    "        # --- HTML Generation and Display ---\n",
    "        html_output = _generate_submission_html(\n",
    "            sub_num, submission, sorted_defects_df, temp_models, items, defects\n",
    "        )\n",
    "        display(HTML(html_output))\n",
    "            \n",
    "        # --- 3. Update Models ---\n",
    "        # The update is called on the single Series submission and defect_counts\n",
    "        for model in temp_models.values():\n",
    "            model.update(submission, defect_counts)\n",
    "            \n",
    "    print(f\"--- PILOT TEST COMPLETE FOR USER: {user_id} ---\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pilot_test_user(test_log.iloc[110]['user'], models, test_log, test_defect_log, items, defects)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
